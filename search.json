[
  {
    "objectID": "website/tutorial04.html",
    "href": "website/tutorial04.html",
    "title": "WrightMap Tutorial - Part 4",
    "section": "",
    "text": "In this part of the tutorial, we’ll show how to load ConQuest output to make a CQmodel object and then WrightMaps. We’ll also show how to turn deltas into thresholds. All the example files here are available in the /inst/extdata folder of our GitHub site. If you download the latest version of the package, they should be in a folder called /extdata wherever your R packages are stored. You can set this folder as your working directory with setwd() or use the system.file() command—as in the next set of examples—to run them.\n\n\n\nLet’s load a model. The first parameter should be the name of the person estimates file, while the second should be the name of the show file. Both are necessary for creating Wright maps (although the CQmodel function will run fine with only one or the other, provided that they are properly passed).\nWe start by loading the WrightMap example files.\n\nfpath &lt;- system.file(\"extdata\", \"ex2.SHW\",package=\"WrightMap\")\n\nAnd we load the example output.\nmodel1 &lt;- CQmodel(p.est = (system.file(\"extdata\", \"ex2.eap\",package=\"WrightMap\"))\n    , show = (system.file(\"extdata\", \"ex2.SHW\",package=\"WrightMap\")))\nThis (model1) is a CQmodel object. Enter the name of the object to see the names of all the tables & information stored within this object.\n\nmodel1\n\n\nConQuest Output Summary:\n========================\nPartial Credit Analysis \n\nThe item model: item+item*step \n1 dimension \n582 participants\nDeviance: 9272.597 (21 parameters)\n\nAdditional information available:\nSummary of estimation: $SOE\nResponse model parameter estimates: $RMP\nRegression coefficients: $reg.coef\nVariances: $variances\nReliabilities: $rel.coef\nGIN tables (thresholds): $GIN\nEAP table: $p.est\nAdditional details: $run.details\n\n\nType the name of any of these tables to see the information stored there.\n\nmodel1$SOE\n\n\nSummary of estimation\n\nEstimation method: Gauss-Hermite Quadrature with 15 nodes \nAssumed population distribution: Gaussian \nConstraint: DEFAULT \n\nTermination criteria:\n      1000 iterations\n      0.0001 change in parameters\n      0.0001 change in deviance\n      100 iterations without a deviance improvement\n      10 Newton steps in M-step\nEstimation terminated after 27 iterations because the deviance convergence criteria was reached.\n\nRandom number generation seed: 1 \n2000 nodes used for drawing 5 plausible values \n200 nodes used when computing fit \nValue for obtaining finite MLEs for zero/perfects: 0.3 \n\nmodel1$equation\n\n[1] \"item+item*step\"\n\nmodel1$reg.coef\n\n               CONSTANT\nMain dimension    0.972\nS. errors         0.062\n\nmodel1$rel.coef\n\n               MLE Person separation RELIABILITY\nMain dimension NA                               \n               WLE Person separation RELIABILITY EAP/PV RELIABILITY\nMain dimension NA                                0.813             \n\nmodel1$variances\n\n           errors\n[1,] 2.162     NA\n\n\nThe most relevant for our purposes are the RMP, GIN, and p.est tables. The RMP tables contain the Response Model Parameters. These are item parameters. Typing model1$RMP would display them, but they’re a little long, so I’m just going to ask for the names and then show the first few rows of each table.\n\nnames(model1$RMP)\n\n[1] \"item\"      \"item*step\"\n\n\nFor this model, the RMPs have item and item*step parameters. We could add these to get the deltas. Let’s see what the tables look like.\n\nhead(model1$RMP$item)\n\n  n_item item    est error U.fit U.Low U.High  U.T W.fit W.Low W.High  W.T\n1      1    1  0.753 0.055  1.11  0.88   1.12  1.8  1.10  0.89   1.11  1.8\n2      2    2  1.068 0.053  1.41  0.88   1.12  6.0  1.37  0.89   1.11  6.0\n3      3    3 -0.524 0.058  0.82  0.88   1.12 -3.2  0.87  0.88   1.12 -2.3\n4      4    4 -1.174 0.060  0.76  0.88   1.12 -4.3  0.85  0.88   1.12 -2.7\n5      5    5 -0.389 0.057  0.95  0.88   1.12 -0.9  0.95  0.89   1.11 -0.9\n6      6    6  0.067 0.055  1.03  0.88   1.12  0.6  1.02  0.89   1.11  0.3\n\nhead(model1$RMP$\"item*step\")\n\n  n_item item step    est error U.fit U.Low U.High  U.T W.fit W.Low W.High  W.T\n1      1    1    0     NA    NA  2.03  0.88   1.12 13.3  1.18  0.89   1.11  3.0\n2      1    1    1 -1.129 0.090  0.99  0.88   1.12 -0.1  1.00  0.95   1.05  0.0\n3      1    1    2  1.129    NA  0.80  0.88   1.12 -3.5  0.95  0.89   1.11 -0.9\n4      2    2    0     NA    NA  2.25  0.88   1.12 15.4  1.40  0.90   1.10  7.1\n5      2    2    1 -0.626 0.093  1.04  0.88   1.12  0.7  1.04  0.94   1.06  1.3\n6      2    2    2  0.626    NA  1.08  0.88   1.12  1.2  1.08  0.89   1.11  1.4\n\n\nLet’s look at a more complicated example.\nmodel2 &lt;- CQmodel(file.path(fpath, \"ex4a.mle\"), file.path(fpath, \"ex4a.shw\"))\n\nmodel2$equation\n\n[1] \"rater+topic+criteria+rater*topic+rater*criteria+topic*criteria+rater*topic*criteria*step\"\n\nnames(model2$RMP)\n\n[1] \"rater\"                     \"topic\"                    \n[3] \"criteria\"                  \"rater*topic\"              \n[5] \"rater*criteria\"            \"topic*criteria\"           \n[7] \"rater*topic*criteria*step\"\n\nhead(model2$RMP$\"rater*topic*criteria*step\")\n\n  n_rater    rater n_topic topic n_criteria criteria step    est error U.fit\n1       1      Amy       1 Sport          1 spelling    1     NA    NA  0.43\n2       1      Amy       1 Sport          1 spelling    2  0.299 0.398  1.34\n3       1      Amy       1 Sport          1 spelling    3 -0.299    NA  1.28\n4       2 Beverely       1 Sport          1 spelling    0     NA    NA  0.41\n5       2 Beverely       1 Sport          1 spelling    1 -0.184 0.491  3.23\n6       2 Beverely       1 Sport          1 spelling    2  0.051 0.461  0.87\n  U.Low U.High  U.T W.fit W.Low W.High W.T\n1  0.70   1.30 -4.7  0.99  0.00   2.00 0.1\n2  0.70   1.30  2.1  1.05  0.42   1.58 0.3\n3  0.70   1.30  1.7  1.05  0.51   1.49 0.3\n4  0.74   1.26 -5.8  1.47  0.00   2.09 0.9\n5  0.74   1.26 10.9  0.95  0.30   1.70 0.0\n6  0.74   1.26 -1.0  1.30  0.62   1.38 1.5\n\n\nThe GIN tables show the threshold parameters.\n\nmodel1$GIN\n\n          [,1]  [,2]\nItem_1  -0.469 1.977\nItem_2   0.234 1.906\nItem_3  -1.789 0.742\nItem_4  -2.688 0.336\nItem_5  -1.656 0.883\nItem_6  -1.063 1.195\nItem_7  -1.969 1.047\nItem_8  -1.617 1.289\nItem_9  -0.957 1.508\nItem_10 -0.992 2.094\n\nmodel2$GIN\n\n$Amy\n$Amy$Sport\n             [,1]   [,2]   [,3]\nspelling  -31.996 -1.976 -1.250\ncoherence  -1.447 -1.446 -1.209\nstructure  -2.247 -0.911 -0.172\ngrammar    -0.885 -0.773 -0.107\ncontent    -0.486  0.104  0.627\n\n$Amy$Family\n             [,1]   [,2]   [,3]\nspelling  -31.996 -2.516 -0.912\ncoherence  -1.401 -1.280 -1.103\nstructure  -1.966 -1.260 -0.294\ngrammar    -1.069 -0.380 -0.106\ncontent    -0.728 -0.012  0.950\n\n$Amy$Work\n            [,1]   [,2]   [,3]\nspelling  -2.055 -2.051 -1.128\ncoherence -1.515 -1.320 -0.862\nstructure -1.402 -1.158 -0.631\ngrammar   -0.816 -0.550  0.122\ncontent   -0.430  0.212  0.762\n\n$Amy$School\n             [,1]   [,2]   [,3]\nspelling  -31.996 -2.059 -0.997\ncoherence  -1.403 -1.402 -0.999\nstructure  -1.629 -1.148 -0.462\ngrammar    -0.967 -0.421  0.070\ncontent    -0.782 -0.027  1.121\n\n\n$Beverely\n$Beverely$Sport\n            [,1]   [,2]   [,3]\nspelling  -2.054 -1.339 -0.663\ncoherence -1.751 -1.129 -0.674\nstructure -1.042 -0.437  0.013\ngrammar   -0.502 -0.082  0.529\ncontent   -0.253  0.613  1.184\n\n$Beverely$Family\n             [,1]   [,2]   [,3]\nspelling  -31.996 -2.264 -0.718\ncoherence  -1.524 -1.357 -0.684\nstructure  -1.326 -0.577  0.164\ngrammar    -0.796  0.118  0.599\ncontent    -0.469  0.690  1.230\n\n$Beverely$Work\n            [,1]   [,2]   [,3]\nspelling  -2.366 -1.465 -0.672\ncoherence -1.388 -1.088 -0.925\nstructure -1.115 -0.621  0.197\ngrammar   -0.345  0.045  0.495\ncontent   -0.212  0.482  1.282\n\n$Beverely$School\n            [,1]   [,2]   [,3]\nspelling  -1.826 -1.611 -0.873\ncoherence -1.632 -1.222 -0.794\nstructure -1.270 -0.865  0.321\ngrammar   -0.491 -0.037  0.413\ncontent   -0.361  0.449  1.137\n\n\n$Colin\n$Colin$Sport\n            [,1]   [,2]  [,3]\nspelling  -1.660 -0.685 0.564\ncoherence -0.612 -0.168 0.362\nstructure -0.485  0.519 1.512\ngrammar    0.611  1.275 1.698\ncontent    1.037  1.853 2.343\n\n$Colin$Family\n            [,1]   [,2]   [,3]\nspelling  -1.477 -0.677 -0.022\ncoherence -0.441 -0.277  0.332\nstructure -0.318  0.265  1.299\ngrammar    0.361  1.252  1.839\ncontent    1.009  1.683  2.374\n\n$Colin$Work\n            [,1]   [,2]  [,3]\nspelling  -1.697 -1.002 0.089\ncoherence -0.654 -0.105 0.192\nstructure -0.502  0.502 1.205\ngrammar    0.662  1.218 1.573\ncontent    0.766  1.806 2.357\n\n$Colin$School\n            [,1]   [,2]  [,3]\nspelling  -1.595 -0.788 0.095\ncoherence -0.629 -0.389 0.123\nstructure -0.470  0.122 1.237\ngrammar    0.385  1.010 1.679\ncontent    0.698  1.520 2.310\n\n\n$David\n$David$Sport\n            [,1]   [,2]  [,3]\nspelling  -1.405 -0.482 0.412\ncoherence -0.357  0.136 0.581\nstructure  0.023  0.724 1.811\ngrammar    0.714  1.454 1.959\ncontent    1.256  2.031 2.912\n\n$David$Family\n            [,1]   [,2]  [,3]\nspelling  -1.271 -0.404 0.741\ncoherence  0.028  0.415 0.977\nstructure  0.474  1.069 1.756\ngrammar    1.177  1.733 2.085\ncontent    1.284  2.169 3.596\n\n$David$Work\n            [,1]   [,2]  [,3]\nspelling  -1.378 -0.587 0.498\ncoherence -0.119  0.260 0.795\nstructure  0.173  1.003 1.885\ngrammar    1.199  1.592 2.008\ncontent    1.437  2.174 3.117\n\n$David$School\n            [,1]   [,2]  [,3]\nspelling  -0.815 -0.330 0.424\ncoherence  0.062  0.293 0.805\nstructure  0.295  1.012 1.955\ngrammar    1.035  1.642 2.260\ncontent    1.312  2.107 3.407\n\n\nFinally, the p.est table shows person parameters.\n\nhead(model1$p.est)  ##EAPs\n\n  casenum est (d1) error (d1) pop (d1)\n1       1 -0.08240    0.50495  0.88205\n2       2  1.75925    0.55966  0.85510\n3       3  0.16483    0.49122  0.88838\n4       4  3.57343    0.82692  0.68367\n5       5 -0.62303    0.52908  0.87051\n6       6  0.16483    0.49122  0.88838\n\nhead(model2$p.est)  ##MLEs\n\n  casenum sscore (d1) max (d1) est (d1) error (d1)\n1       1          23       60 -0.49687    0.25349\n2       2          36       60  0.69311    0.26051\n3       3          24       60 -0.26371    0.26378\n4       4          52       60  1.85869    0.37825\n5       5          47       60  1.91466    0.28843\n6       6          47       60  0.53122    0.28348\n\n\n\n\n\nOk, we have person parameters and item parameters: Let’s make a Wright Map.\n\nwrightMap(model1)\n\nUsing GIN table for threshold parameters\n\n\n\n\n\n\n\n\n\nThe above uses the GIN table as thresholds. But you may want to use RMP tables. For example, if you have an item table and an itemstep table, you might want to combine them to make deltas. You could do this yourself, but you could also let the make.deltas function do it for you. This function reshapes the itemstep parameters, checks the item numbers to see if there are any dichotomous items, and then adds the steps and items. This can be especially useful if you didn’t get a GIN table from ConQuest (see below).\nmodel3 &lt;- CQmodel(file.path(fpath, \"ex2a.eap\"), file.path(fpath, \"ex2a.shw\"))\n\nmodel3$GIN\n\nNULL\n\nmodel3$equation\n\n[1] \"item+item*step\"\n\nmake.deltas(model3)\n\n                   1      2      3\nEarth shape   -0.961 -0.493     NA\nEarth pictu.. -0.650  0.256  2.704\nFalling off   -1.416  1.969  1.265\nWhat is Sun   -0.959  1.343     NA\nMoonshine      0.157 -0.482 -0.128\nMoon and ni.. -0.635  0.861     NA\nNight and d..  0.157 -0.075 -0.739\nBreathe on ..  0.657  1.152 -3.558\n\n\nWhen sent a model with no GIN table, wrightMap will automatically send it to make.deltas without the user having to ask.\n\nwrightMap(model3, label.items.row = 2)\n\n\n\n\n\n\n\n\nThe make.deltas function can also handle rating scale models.\nmodel4 &lt;- CQmodel(file.path(fpath, \"ex2b.eap\"), file.path(fpath, \"ex2b-2.shw\"))\n\nmodel4$GIN\n\nNULL\n\nmodel4$equation\n\n[1] \"item+step\"\n\nmake.deltas(model4)\n\n                   1     2\nCurriculum .. -0.468 1.900\nNot Until E.. -0.123 2.245\nFinancial R.. -1.743 0.625\nStaff Commi.. -2.230 0.138\nCommitment .. -1.609 0.759\nRun for som.. -1.193 1.175\nAchievable .. -1.570 0.798\nPrincipals .. -1.317 1.051\nParents sup.. -0.952 1.416\nStudent mot.. -0.636 1.732\n\n\nOr let wrightMap make them automatically.\n\nwrightMap(model4, label.items.row = 2)\n\n\n\n\n\n\n\n\n\n\n\nIn the above examples, we let wrightMap decide what parameters to graph. wrightMap starts by looking for a GIN table. If it finds that, it assumes they are thresholds and graphs them accordingly. If there is no GIN table, it then sends the function to make.deltas, which will examine the model equation to see if it knows how to handle it. Make.deltas can handle equations of the form:\nA (e.g. `item`)\nA + B (e.g. `item + step` [RSM])\nA + A * B (e.g. `item + item * step` [PCM])\nA + A * B + B (e.g `item + item * gender + gender`)\nBut sometimes we may want something other than the default. Let’s look at model2 again.\n\nmodel2$equation\n\n[1] \"rater+topic+criteria+rater*topic+rater*criteria+topic*criteria+rater*topic*criteria*step\"\n\n\nHere’s the default Wright Map, using the GIN table:\n\nwrightMap(model2, min.logit.pad = -29)\n\nUsing GIN table for threshold parameters\n\n\n\n\n\n\n\n\n\nThis doesn’t look great. Instead of showing all these estimates, we can specify a specific RMP table to use using the item.table parameter.\n\nwrightMap(model2, item.table = \"rater\")\n\n\n\n\n\n\n\n\nThat shows just the rater parameters. Here’s just the topics.\n\nwrightMap(model2, item.table = \"topic\")\n\n\n\n\n\n\n\n\nWhat I really want, though, is to show the rater*topic estimates. For this, we can use the interactions and step.table parameters.\n\nwrightMap(model2, item.table = \"rater\", interactions = \"rater*topic\",\n    step.table = \"topic\")\n\n\n\n\n\n\n\n\nSwitch the item and step names to graph it the other way:\n\nwrightMap(model2, item.table = \"topic\", interactions = \"rater*topic\",\n    step.table = \"rater\")\n\n\n\n\n\n\n\n\nYou can leave out the interactions to have more of a rating scale-type model.\n\nwrightMap(model2, item.table = \"rater\", step.table = \"topic\")\n\n\n\n\n\n\n\n\nOr leave out the step table:\n\nwrightMap(model2, item.table = \"rater\", interactions = \"rater*topic\")\n\n\n\n\n\n\n\n\nAgain, make.deltas is reading the model equation to decide whether to add or subtract. If, for some reason, you want to specify a different sign for one of the tables, you can use item.sign, step.sign, and inter.sign for that.\n\nwrightMap(model2, item.table = \"rater\", interactions = \"rater*topic\",\n    step.table = \"topic\", step.sign = -1)\n\n\n\n\n\n\n\n\n\n\n\nSo far, we’ve seen how to use the GIN table to graph thresholds, or the RMP tables to graph deltas. We have one use case left: Making thresholds out of those RMP-generated deltas. The make.thresholds function can handle this. The example below uses the model3 deltas, but you can send it any matrix with items as rows and steps as columns.\n\ndeltas &lt;- make.deltas(model3)\ndeltas\n\n                   1      2      3\nEarth shape   -0.961 -0.493     NA\nEarth pictu.. -0.650  0.256  2.704\nFalling off   -1.416  1.969  1.265\nWhat is Sun   -0.959  1.343     NA\nMoonshine      0.157 -0.482 -0.128\nMoon and ni.. -0.635  0.861     NA\nNight and d..  0.157 -0.075 -0.739\nBreathe on ..  0.657  1.152 -3.558\n\nmake.thresholds(deltas)\n\nAssuming partial credit model\n\n\n                    [,1]       [,2]       [,3]\nEarth shape   -1.3229164 -0.1310804         NA\nEarth pictu.. -0.9241595  0.4451567  2.7832333\nFalling off   -1.4503041  1.3141486  1.9728871\nWhat is Sun   -1.0466830  1.4306938         NA\nMoonshine     -0.6759150 -0.2252513  0.4156190\nMoon and ni.. -0.8076978  1.0336795         NA\nNight and d.. -0.6343026 -0.1937096  0.1852925\nBreathe on .. -0.7007363 -0.5078997 -0.4741583\n\n\nAlternately, we can just send the model object directly:\n\nmake.thresholds(model3)\n\nAssuming partial credit model\n\n\n                    [,1]       [,2]       [,3]\nEarth shape   -1.3229164 -0.1310804         NA\nEarth pictu.. -0.9241595  0.4451567  2.7832333\nFalling off   -1.4503041  1.3141486  1.9728871\nWhat is Sun   -1.0466830  1.4306938         NA\nMoonshine     -0.6759150 -0.2252513  0.4156190\nMoon and ni.. -0.8076978  1.0336795         NA\nNight and d.. -0.6343026 -0.1937096  0.1852925\nBreathe on .. -0.7007363 -0.5078997 -0.4741583\n\n\nYou don’t have to do any of this to make a Wright Map. You can just send the model to wrightMap, and use the type parameter to ask it to calculate the thresholds for you.\n\nwrightMap(model3, type = \"thresholds\", label.items.row = 2)\n\n\n\n\n\n\n\n\nFinally: If all you want is the Wright Maps, you can skip CQmodel entirely and just send your files to wrightMap.\nwrightMap(file.path(fpath,\"ex2a.eap\"), file.path(fpath,\"ex2.shw\"), label.items.row = 3)\n\nwrightMap(\n    file.path(\"https://raw.githubusercontent.com/david-ti/wrightmap/refs/heads/master/inst/extdata/ex2a.eap\"), \n    file.path(\"https://raw.githubusercontent.com/david-ti/wrightmap/refs/heads/master/inst/extdata/ex2a.shw\")\n        , label.items.row = 3)"
  },
  {
    "objectID": "website/tutorial04.html#using-conquest-output-and-making-thresholds",
    "href": "website/tutorial04.html#using-conquest-output-and-making-thresholds",
    "title": "WrightMap Tutorial - Part 4",
    "section": "",
    "text": "In this part of the tutorial, we’ll show how to load ConQuest output to make a CQmodel object and then WrightMaps. We’ll also show how to turn deltas into thresholds. All the example files here are available in the /inst/extdata folder of our GitHub site. If you download the latest version of the package, they should be in a folder called /extdata wherever your R packages are stored. You can set this folder as your working directory with setwd() or use the system.file() command—as in the next set of examples—to run them.\n\n\n\nLet’s load a model. The first parameter should be the name of the person estimates file, while the second should be the name of the show file. Both are necessary for creating Wright maps (although the CQmodel function will run fine with only one or the other, provided that they are properly passed).\nWe start by loading the WrightMap example files.\n\nfpath &lt;- system.file(\"extdata\", \"ex2.SHW\",package=\"WrightMap\")\n\nAnd we load the example output.\nmodel1 &lt;- CQmodel(p.est = (system.file(\"extdata\", \"ex2.eap\",package=\"WrightMap\"))\n    , show = (system.file(\"extdata\", \"ex2.SHW\",package=\"WrightMap\")))\nThis (model1) is a CQmodel object. Enter the name of the object to see the names of all the tables & information stored within this object.\n\nmodel1\n\n\nConQuest Output Summary:\n========================\nPartial Credit Analysis \n\nThe item model: item+item*step \n1 dimension \n582 participants\nDeviance: 9272.597 (21 parameters)\n\nAdditional information available:\nSummary of estimation: $SOE\nResponse model parameter estimates: $RMP\nRegression coefficients: $reg.coef\nVariances: $variances\nReliabilities: $rel.coef\nGIN tables (thresholds): $GIN\nEAP table: $p.est\nAdditional details: $run.details\n\n\nType the name of any of these tables to see the information stored there.\n\nmodel1$SOE\n\n\nSummary of estimation\n\nEstimation method: Gauss-Hermite Quadrature with 15 nodes \nAssumed population distribution: Gaussian \nConstraint: DEFAULT \n\nTermination criteria:\n      1000 iterations\n      0.0001 change in parameters\n      0.0001 change in deviance\n      100 iterations without a deviance improvement\n      10 Newton steps in M-step\nEstimation terminated after 27 iterations because the deviance convergence criteria was reached.\n\nRandom number generation seed: 1 \n2000 nodes used for drawing 5 plausible values \n200 nodes used when computing fit \nValue for obtaining finite MLEs for zero/perfects: 0.3 \n\nmodel1$equation\n\n[1] \"item+item*step\"\n\nmodel1$reg.coef\n\n               CONSTANT\nMain dimension    0.972\nS. errors         0.062\n\nmodel1$rel.coef\n\n               MLE Person separation RELIABILITY\nMain dimension NA                               \n               WLE Person separation RELIABILITY EAP/PV RELIABILITY\nMain dimension NA                                0.813             \n\nmodel1$variances\n\n           errors\n[1,] 2.162     NA\n\n\nThe most relevant for our purposes are the RMP, GIN, and p.est tables. The RMP tables contain the Response Model Parameters. These are item parameters. Typing model1$RMP would display them, but they’re a little long, so I’m just going to ask for the names and then show the first few rows of each table.\n\nnames(model1$RMP)\n\n[1] \"item\"      \"item*step\"\n\n\nFor this model, the RMPs have item and item*step parameters. We could add these to get the deltas. Let’s see what the tables look like.\n\nhead(model1$RMP$item)\n\n  n_item item    est error U.fit U.Low U.High  U.T W.fit W.Low W.High  W.T\n1      1    1  0.753 0.055  1.11  0.88   1.12  1.8  1.10  0.89   1.11  1.8\n2      2    2  1.068 0.053  1.41  0.88   1.12  6.0  1.37  0.89   1.11  6.0\n3      3    3 -0.524 0.058  0.82  0.88   1.12 -3.2  0.87  0.88   1.12 -2.3\n4      4    4 -1.174 0.060  0.76  0.88   1.12 -4.3  0.85  0.88   1.12 -2.7\n5      5    5 -0.389 0.057  0.95  0.88   1.12 -0.9  0.95  0.89   1.11 -0.9\n6      6    6  0.067 0.055  1.03  0.88   1.12  0.6  1.02  0.89   1.11  0.3\n\nhead(model1$RMP$\"item*step\")\n\n  n_item item step    est error U.fit U.Low U.High  U.T W.fit W.Low W.High  W.T\n1      1    1    0     NA    NA  2.03  0.88   1.12 13.3  1.18  0.89   1.11  3.0\n2      1    1    1 -1.129 0.090  0.99  0.88   1.12 -0.1  1.00  0.95   1.05  0.0\n3      1    1    2  1.129    NA  0.80  0.88   1.12 -3.5  0.95  0.89   1.11 -0.9\n4      2    2    0     NA    NA  2.25  0.88   1.12 15.4  1.40  0.90   1.10  7.1\n5      2    2    1 -0.626 0.093  1.04  0.88   1.12  0.7  1.04  0.94   1.06  1.3\n6      2    2    2  0.626    NA  1.08  0.88   1.12  1.2  1.08  0.89   1.11  1.4\n\n\nLet’s look at a more complicated example.\nmodel2 &lt;- CQmodel(file.path(fpath, \"ex4a.mle\"), file.path(fpath, \"ex4a.shw\"))\n\nmodel2$equation\n\n[1] \"rater+topic+criteria+rater*topic+rater*criteria+topic*criteria+rater*topic*criteria*step\"\n\nnames(model2$RMP)\n\n[1] \"rater\"                     \"topic\"                    \n[3] \"criteria\"                  \"rater*topic\"              \n[5] \"rater*criteria\"            \"topic*criteria\"           \n[7] \"rater*topic*criteria*step\"\n\nhead(model2$RMP$\"rater*topic*criteria*step\")\n\n  n_rater    rater n_topic topic n_criteria criteria step    est error U.fit\n1       1      Amy       1 Sport          1 spelling    1     NA    NA  0.43\n2       1      Amy       1 Sport          1 spelling    2  0.299 0.398  1.34\n3       1      Amy       1 Sport          1 spelling    3 -0.299    NA  1.28\n4       2 Beverely       1 Sport          1 spelling    0     NA    NA  0.41\n5       2 Beverely       1 Sport          1 spelling    1 -0.184 0.491  3.23\n6       2 Beverely       1 Sport          1 spelling    2  0.051 0.461  0.87\n  U.Low U.High  U.T W.fit W.Low W.High W.T\n1  0.70   1.30 -4.7  0.99  0.00   2.00 0.1\n2  0.70   1.30  2.1  1.05  0.42   1.58 0.3\n3  0.70   1.30  1.7  1.05  0.51   1.49 0.3\n4  0.74   1.26 -5.8  1.47  0.00   2.09 0.9\n5  0.74   1.26 10.9  0.95  0.30   1.70 0.0\n6  0.74   1.26 -1.0  1.30  0.62   1.38 1.5\n\n\nThe GIN tables show the threshold parameters.\n\nmodel1$GIN\n\n          [,1]  [,2]\nItem_1  -0.469 1.977\nItem_2   0.234 1.906\nItem_3  -1.789 0.742\nItem_4  -2.688 0.336\nItem_5  -1.656 0.883\nItem_6  -1.063 1.195\nItem_7  -1.969 1.047\nItem_8  -1.617 1.289\nItem_9  -0.957 1.508\nItem_10 -0.992 2.094\n\nmodel2$GIN\n\n$Amy\n$Amy$Sport\n             [,1]   [,2]   [,3]\nspelling  -31.996 -1.976 -1.250\ncoherence  -1.447 -1.446 -1.209\nstructure  -2.247 -0.911 -0.172\ngrammar    -0.885 -0.773 -0.107\ncontent    -0.486  0.104  0.627\n\n$Amy$Family\n             [,1]   [,2]   [,3]\nspelling  -31.996 -2.516 -0.912\ncoherence  -1.401 -1.280 -1.103\nstructure  -1.966 -1.260 -0.294\ngrammar    -1.069 -0.380 -0.106\ncontent    -0.728 -0.012  0.950\n\n$Amy$Work\n            [,1]   [,2]   [,3]\nspelling  -2.055 -2.051 -1.128\ncoherence -1.515 -1.320 -0.862\nstructure -1.402 -1.158 -0.631\ngrammar   -0.816 -0.550  0.122\ncontent   -0.430  0.212  0.762\n\n$Amy$School\n             [,1]   [,2]   [,3]\nspelling  -31.996 -2.059 -0.997\ncoherence  -1.403 -1.402 -0.999\nstructure  -1.629 -1.148 -0.462\ngrammar    -0.967 -0.421  0.070\ncontent    -0.782 -0.027  1.121\n\n\n$Beverely\n$Beverely$Sport\n            [,1]   [,2]   [,3]\nspelling  -2.054 -1.339 -0.663\ncoherence -1.751 -1.129 -0.674\nstructure -1.042 -0.437  0.013\ngrammar   -0.502 -0.082  0.529\ncontent   -0.253  0.613  1.184\n\n$Beverely$Family\n             [,1]   [,2]   [,3]\nspelling  -31.996 -2.264 -0.718\ncoherence  -1.524 -1.357 -0.684\nstructure  -1.326 -0.577  0.164\ngrammar    -0.796  0.118  0.599\ncontent    -0.469  0.690  1.230\n\n$Beverely$Work\n            [,1]   [,2]   [,3]\nspelling  -2.366 -1.465 -0.672\ncoherence -1.388 -1.088 -0.925\nstructure -1.115 -0.621  0.197\ngrammar   -0.345  0.045  0.495\ncontent   -0.212  0.482  1.282\n\n$Beverely$School\n            [,1]   [,2]   [,3]\nspelling  -1.826 -1.611 -0.873\ncoherence -1.632 -1.222 -0.794\nstructure -1.270 -0.865  0.321\ngrammar   -0.491 -0.037  0.413\ncontent   -0.361  0.449  1.137\n\n\n$Colin\n$Colin$Sport\n            [,1]   [,2]  [,3]\nspelling  -1.660 -0.685 0.564\ncoherence -0.612 -0.168 0.362\nstructure -0.485  0.519 1.512\ngrammar    0.611  1.275 1.698\ncontent    1.037  1.853 2.343\n\n$Colin$Family\n            [,1]   [,2]   [,3]\nspelling  -1.477 -0.677 -0.022\ncoherence -0.441 -0.277  0.332\nstructure -0.318  0.265  1.299\ngrammar    0.361  1.252  1.839\ncontent    1.009  1.683  2.374\n\n$Colin$Work\n            [,1]   [,2]  [,3]\nspelling  -1.697 -1.002 0.089\ncoherence -0.654 -0.105 0.192\nstructure -0.502  0.502 1.205\ngrammar    0.662  1.218 1.573\ncontent    0.766  1.806 2.357\n\n$Colin$School\n            [,1]   [,2]  [,3]\nspelling  -1.595 -0.788 0.095\ncoherence -0.629 -0.389 0.123\nstructure -0.470  0.122 1.237\ngrammar    0.385  1.010 1.679\ncontent    0.698  1.520 2.310\n\n\n$David\n$David$Sport\n            [,1]   [,2]  [,3]\nspelling  -1.405 -0.482 0.412\ncoherence -0.357  0.136 0.581\nstructure  0.023  0.724 1.811\ngrammar    0.714  1.454 1.959\ncontent    1.256  2.031 2.912\n\n$David$Family\n            [,1]   [,2]  [,3]\nspelling  -1.271 -0.404 0.741\ncoherence  0.028  0.415 0.977\nstructure  0.474  1.069 1.756\ngrammar    1.177  1.733 2.085\ncontent    1.284  2.169 3.596\n\n$David$Work\n            [,1]   [,2]  [,3]\nspelling  -1.378 -0.587 0.498\ncoherence -0.119  0.260 0.795\nstructure  0.173  1.003 1.885\ngrammar    1.199  1.592 2.008\ncontent    1.437  2.174 3.117\n\n$David$School\n            [,1]   [,2]  [,3]\nspelling  -0.815 -0.330 0.424\ncoherence  0.062  0.293 0.805\nstructure  0.295  1.012 1.955\ngrammar    1.035  1.642 2.260\ncontent    1.312  2.107 3.407\n\n\nFinally, the p.est table shows person parameters.\n\nhead(model1$p.est)  ##EAPs\n\n  casenum est (d1) error (d1) pop (d1)\n1       1 -0.08240    0.50495  0.88205\n2       2  1.75925    0.55966  0.85510\n3       3  0.16483    0.49122  0.88838\n4       4  3.57343    0.82692  0.68367\n5       5 -0.62303    0.52908  0.87051\n6       6  0.16483    0.49122  0.88838\n\nhead(model2$p.est)  ##MLEs\n\n  casenum sscore (d1) max (d1) est (d1) error (d1)\n1       1          23       60 -0.49687    0.25349\n2       2          36       60  0.69311    0.26051\n3       3          24       60 -0.26371    0.26378\n4       4          52       60  1.85869    0.37825\n5       5          47       60  1.91466    0.28843\n6       6          47       60  0.53122    0.28348\n\n\n\n\n\nOk, we have person parameters and item parameters: Let’s make a Wright Map.\n\nwrightMap(model1)\n\nUsing GIN table for threshold parameters\n\n\n\n\n\n\n\n\n\nThe above uses the GIN table as thresholds. But you may want to use RMP tables. For example, if you have an item table and an itemstep table, you might want to combine them to make deltas. You could do this yourself, but you could also let the make.deltas function do it for you. This function reshapes the itemstep parameters, checks the item numbers to see if there are any dichotomous items, and then adds the steps and items. This can be especially useful if you didn’t get a GIN table from ConQuest (see below).\nmodel3 &lt;- CQmodel(file.path(fpath, \"ex2a.eap\"), file.path(fpath, \"ex2a.shw\"))\n\nmodel3$GIN\n\nNULL\n\nmodel3$equation\n\n[1] \"item+item*step\"\n\nmake.deltas(model3)\n\n                   1      2      3\nEarth shape   -0.961 -0.493     NA\nEarth pictu.. -0.650  0.256  2.704\nFalling off   -1.416  1.969  1.265\nWhat is Sun   -0.959  1.343     NA\nMoonshine      0.157 -0.482 -0.128\nMoon and ni.. -0.635  0.861     NA\nNight and d..  0.157 -0.075 -0.739\nBreathe on ..  0.657  1.152 -3.558\n\n\nWhen sent a model with no GIN table, wrightMap will automatically send it to make.deltas without the user having to ask.\n\nwrightMap(model3, label.items.row = 2)\n\n\n\n\n\n\n\n\nThe make.deltas function can also handle rating scale models.\nmodel4 &lt;- CQmodel(file.path(fpath, \"ex2b.eap\"), file.path(fpath, \"ex2b-2.shw\"))\n\nmodel4$GIN\n\nNULL\n\nmodel4$equation\n\n[1] \"item+step\"\n\nmake.deltas(model4)\n\n                   1     2\nCurriculum .. -0.468 1.900\nNot Until E.. -0.123 2.245\nFinancial R.. -1.743 0.625\nStaff Commi.. -2.230 0.138\nCommitment .. -1.609 0.759\nRun for som.. -1.193 1.175\nAchievable .. -1.570 0.798\nPrincipals .. -1.317 1.051\nParents sup.. -0.952 1.416\nStudent mot.. -0.636 1.732\n\n\nOr let wrightMap make them automatically.\n\nwrightMap(model4, label.items.row = 2)\n\n\n\n\n\n\n\n\n\n\n\nIn the above examples, we let wrightMap decide what parameters to graph. wrightMap starts by looking for a GIN table. If it finds that, it assumes they are thresholds and graphs them accordingly. If there is no GIN table, it then sends the function to make.deltas, which will examine the model equation to see if it knows how to handle it. Make.deltas can handle equations of the form:\nA (e.g. `item`)\nA + B (e.g. `item + step` [RSM])\nA + A * B (e.g. `item + item * step` [PCM])\nA + A * B + B (e.g `item + item * gender + gender`)\nBut sometimes we may want something other than the default. Let’s look at model2 again.\n\nmodel2$equation\n\n[1] \"rater+topic+criteria+rater*topic+rater*criteria+topic*criteria+rater*topic*criteria*step\"\n\n\nHere’s the default Wright Map, using the GIN table:\n\nwrightMap(model2, min.logit.pad = -29)\n\nUsing GIN table for threshold parameters\n\n\n\n\n\n\n\n\n\nThis doesn’t look great. Instead of showing all these estimates, we can specify a specific RMP table to use using the item.table parameter.\n\nwrightMap(model2, item.table = \"rater\")\n\n\n\n\n\n\n\n\nThat shows just the rater parameters. Here’s just the topics.\n\nwrightMap(model2, item.table = \"topic\")\n\n\n\n\n\n\n\n\nWhat I really want, though, is to show the rater*topic estimates. For this, we can use the interactions and step.table parameters.\n\nwrightMap(model2, item.table = \"rater\", interactions = \"rater*topic\",\n    step.table = \"topic\")\n\n\n\n\n\n\n\n\nSwitch the item and step names to graph it the other way:\n\nwrightMap(model2, item.table = \"topic\", interactions = \"rater*topic\",\n    step.table = \"rater\")\n\n\n\n\n\n\n\n\nYou can leave out the interactions to have more of a rating scale-type model.\n\nwrightMap(model2, item.table = \"rater\", step.table = \"topic\")\n\n\n\n\n\n\n\n\nOr leave out the step table:\n\nwrightMap(model2, item.table = \"rater\", interactions = \"rater*topic\")\n\n\n\n\n\n\n\n\nAgain, make.deltas is reading the model equation to decide whether to add or subtract. If, for some reason, you want to specify a different sign for one of the tables, you can use item.sign, step.sign, and inter.sign for that.\n\nwrightMap(model2, item.table = \"rater\", interactions = \"rater*topic\",\n    step.table = \"topic\", step.sign = -1)\n\n\n\n\n\n\n\n\n\n\n\nSo far, we’ve seen how to use the GIN table to graph thresholds, or the RMP tables to graph deltas. We have one use case left: Making thresholds out of those RMP-generated deltas. The make.thresholds function can handle this. The example below uses the model3 deltas, but you can send it any matrix with items as rows and steps as columns.\n\ndeltas &lt;- make.deltas(model3)\ndeltas\n\n                   1      2      3\nEarth shape   -0.961 -0.493     NA\nEarth pictu.. -0.650  0.256  2.704\nFalling off   -1.416  1.969  1.265\nWhat is Sun   -0.959  1.343     NA\nMoonshine      0.157 -0.482 -0.128\nMoon and ni.. -0.635  0.861     NA\nNight and d..  0.157 -0.075 -0.739\nBreathe on ..  0.657  1.152 -3.558\n\nmake.thresholds(deltas)\n\nAssuming partial credit model\n\n\n                    [,1]       [,2]       [,3]\nEarth shape   -1.3229164 -0.1310804         NA\nEarth pictu.. -0.9241595  0.4451567  2.7832333\nFalling off   -1.4503041  1.3141486  1.9728871\nWhat is Sun   -1.0466830  1.4306938         NA\nMoonshine     -0.6759150 -0.2252513  0.4156190\nMoon and ni.. -0.8076978  1.0336795         NA\nNight and d.. -0.6343026 -0.1937096  0.1852925\nBreathe on .. -0.7007363 -0.5078997 -0.4741583\n\n\nAlternately, we can just send the model object directly:\n\nmake.thresholds(model3)\n\nAssuming partial credit model\n\n\n                    [,1]       [,2]       [,3]\nEarth shape   -1.3229164 -0.1310804         NA\nEarth pictu.. -0.9241595  0.4451567  2.7832333\nFalling off   -1.4503041  1.3141486  1.9728871\nWhat is Sun   -1.0466830  1.4306938         NA\nMoonshine     -0.6759150 -0.2252513  0.4156190\nMoon and ni.. -0.8076978  1.0336795         NA\nNight and d.. -0.6343026 -0.1937096  0.1852925\nBreathe on .. -0.7007363 -0.5078997 -0.4741583\n\n\nYou don’t have to do any of this to make a Wright Map. You can just send the model to wrightMap, and use the type parameter to ask it to calculate the thresholds for you.\n\nwrightMap(model3, type = \"thresholds\", label.items.row = 2)\n\n\n\n\n\n\n\n\nFinally: If all you want is the Wright Maps, you can skip CQmodel entirely and just send your files to wrightMap.\nwrightMap(file.path(fpath,\"ex2a.eap\"), file.path(fpath,\"ex2.shw\"), label.items.row = 3)\n\nwrightMap(\n    file.path(\"https://raw.githubusercontent.com/david-ti/wrightmap/refs/heads/master/inst/extdata/ex2a.eap\"), \n    file.path(\"https://raw.githubusercontent.com/david-ti/wrightmap/refs/heads/master/inst/extdata/ex2a.shw\")\n        , label.items.row = 3)"
  },
  {
    "objectID": "website/tutorial03.html",
    "href": "website/tutorial03.html",
    "title": "WrightMap Tutorial - Part 3",
    "section": "",
    "text": "In Part 1, we reviewed how to install the package from GitHub and how to customize unidimensional and dichotomous models. Now in Part 2, we’ll look at graphing some more complicated models.\n(See Part 3 for ConQuest integration and making thresholds out of deltas.)\nIn Part 2, we’ll look at graphing some more complicated models. First, let’s generate some thresholds for a multidimensional model. This will be a matrix containing five columns of person estimates.\n\n\n\nWe will need again to load RColorBrewer for this example.\n\ninstall.packages(\"RColorBrewer\")\n\nInstalling package into '/home/runner/work/_temp/Library'\n(as 'lib' is unspecified)\n\nlibrary(RColorBrewer)\n\n\nset.seed(2020)\nmdim.sim.thetas &lt;- matrix(rnorm(5000), ncol = 5)\n\nSince this will be a dichotomous model, we’ll generate a single column for thresholds.\n\nmdim.sim.thresholds &lt;- runif(10, -3, 3)\n\nOkay, let’s see what the Wright Map looks like for this.\n\nwrightMap(mdim.sim.thetas, mdim.sim.thresholds)\n\n\n\n\n\n\n\n\nThat doesn’t look right. Let’s adjust the proportion of the map’s parts.\n\nwrightMap(mdim.sim.thetas, mdim.sim.thresholds, item.prop = 0.5)\n\n\n\n\n\n\n\n\nLet’s change the dimensions names.\n\nwrightMap(mdim.sim.thetas, mdim.sim.thresholds, item.prop = 0.5,\n    dim.names = c(\"Algebra\", \"Calculus\", \"Trig\", \"Stats\", \"Arithmetic\"))\n\n\n\n\n\n\n\n\nAnd let’s give them some color.\n\nwrightMap(mdim.sim.thetas, mdim.sim.thresholds, item.prop = 0.5,\n    dim.names = c(\"Algebra\", \"Calculus\", \"Trig\", \"Stats\", \"Arithmetic\"),\n    dim.color = brewer.pal(5, \"Set1\"))\n\n\n\n\n\n\n\n\nAnd let’s associate the items with each dimension.\n\nwrightMap(mdim.sim.thetas, mdim.sim.thresholds, item.prop = 0.5,\n    dim.names = c(\"Algebra\", \"Calculus\", \"Trig\", \"Stats\", \"Arithmetic\"),\n    dim.color = brewer.pal(5, \"Set1\"), show.thr.lab = FALSE,\n    thr.sym.col.fg = rep(brewer.pal(5, \"Set1\"), each = 2),\n    thr.sym.col.bg = rep(brewer.pal(5, \"Set1\"), each = 2),\n    thr.sym.cex = 2, use.hist = FALSE)\n\nParameter 'use.hist' is deprecated. Please use 'person.side' parameter instead.\n\n\n\n\n\n\n\n\n\n\n\n\nAll right, let’s look at a Rating Scale Model. First, let’s generate three dimensions of person estimates.\n\nrsm.sim.thetas &lt;- data.frame(d1 = rnorm(1000, mean = -0.5, sd = 1), d2 = rnorm(1000, \n    mean = 0, sd = 1), d3 = rnorm(1000, mean = +0.5, sd = 1))\n\nNow let’s generate the thresholds for the polytomous items. We’ll make them a matrix where each row is an item and each column a level.\n\nitems.loc &lt;- sort(rnorm(10))\n\nrsm.sim.thresholds &lt;- data.frame(l1 = items.loc - 1, l2 = items.loc - 0.5,\n    l3 = items.loc + 0.5, l4 = items.loc + 1)\n\nrsm.sim.thresholds\n\n           l1          l2          l3         l4\n1  -3.2296856 -2.72968555 -1.72968555 -1.2296856\n2  -3.0559158 -2.55591580 -1.55591580 -1.0559158\n3  -2.6763974 -2.17639745 -1.17639745 -0.6763974\n4  -1.9108197 -1.41081970 -0.41081970  0.0891803\n5  -1.5635229 -1.06352291 -0.06352291  0.4364771\n6  -1.4238738 -0.92387385  0.07612615  0.5761262\n7  -0.6849163 -0.18491631  0.81508369  1.3150837\n8  -0.4913923  0.00860773  1.00860773  1.5086077\n9  -0.4736099  0.02639011  1.02639011  1.5263901\n10  1.2934064  1.79340639  2.79340639  3.2934064\n\n\nLet’s look at the Wright Map!\n\nwrightMap(rsm.sim.thetas, rsm.sim.thresholds)\n\n\n\n\n\n\n\n\nLet’s assign a color for each level.\n\nitemlevelcolors &lt;- matrix(rep(brewer.pal(4, \"Set1\"), 10), byrow = TRUE, ncol = 4)\n\nitemlevelcolors\n\n      [,1]      [,2]      [,3]      [,4]     \n [1,] \"#E41A1C\" \"#377EB8\" \"#4DAF4A\" \"#984EA3\"\n [2,] \"#E41A1C\" \"#377EB8\" \"#4DAF4A\" \"#984EA3\"\n [3,] \"#E41A1C\" \"#377EB8\" \"#4DAF4A\" \"#984EA3\"\n [4,] \"#E41A1C\" \"#377EB8\" \"#4DAF4A\" \"#984EA3\"\n [5,] \"#E41A1C\" \"#377EB8\" \"#4DAF4A\" \"#984EA3\"\n [6,] \"#E41A1C\" \"#377EB8\" \"#4DAF4A\" \"#984EA3\"\n [7,] \"#E41A1C\" \"#377EB8\" \"#4DAF4A\" \"#984EA3\"\n [8,] \"#E41A1C\" \"#377EB8\" \"#4DAF4A\" \"#984EA3\"\n [9,] \"#E41A1C\" \"#377EB8\" \"#4DAF4A\" \"#984EA3\"\n[10,] \"#E41A1C\" \"#377EB8\" \"#4DAF4A\" \"#984EA3\"\n\n\nAnd now make a Wright Map with them.\n\nwrightMap(rsm.sim.thetas, rsm.sim.thresholds, thr.sym.col.fg = itemlevelcolors,\n    thr.sym.col.bg = itemlevelcolors)\n\n\n\n\n\n\n\n\nBut we also want to indicate which dimension they belong to… with symbols.\n\nitemdimsymbols &lt;- matrix(c(rep(16, 12), rep(17, 12), rep(18, 16)),\n    byrow = TRUE, ncol = 4)\n\nitemdimsymbols\n\n      [,1] [,2] [,3] [,4]\n [1,]   16   16   16   16\n [2,]   16   16   16   16\n [3,]   16   16   16   16\n [4,]   17   17   17   17\n [5,]   17   17   17   17\n [6,]   17   17   17   17\n [7,]   18   18   18   18\n [8,]   18   18   18   18\n [9,]   18   18   18   18\n[10,]   18   18   18   18\n\n\n\nwrightMap(rsm.sim.thetas, rsm.sim.thresholds, show.thr.lab = FALSE,\n    thr.sym.col.fg = itemlevelcolors, thr.sym.col.bg = itemlevelcolors,\n    thr.sym.pch = itemdimsymbols, thr.sym.cex = 2)\n\n\n\n\n\n\n\n\nAdditionally, we may want to clearly indicate which item parameters are associated with each item. We can draw lines that connect all parameters connected to an item using the vertLines parameter.\n\nwrightMap(rsm.sim.thetas, rsm.sim.thresholds, show.thr.lab = FALSE,\n    thr.sym.col.fg = itemlevelcolors, thr.sym.col.bg = itemlevelcolors,\n    thr.sym.pch = itemdimsymbols, thr.sym.cex = 2, vertLines = TRUE)"
  },
  {
    "objectID": "website/tutorial03.html#plotting-multidimensional-polytomous-models",
    "href": "website/tutorial03.html#plotting-multidimensional-polytomous-models",
    "title": "WrightMap Tutorial - Part 3",
    "section": "",
    "text": "In Part 1, we reviewed how to install the package from GitHub and how to customize unidimensional and dichotomous models. Now in Part 2, we’ll look at graphing some more complicated models.\n(See Part 3 for ConQuest integration and making thresholds out of deltas.)\nIn Part 2, we’ll look at graphing some more complicated models. First, let’s generate some thresholds for a multidimensional model. This will be a matrix containing five columns of person estimates.\n\n\n\nWe will need again to load RColorBrewer for this example.\n\ninstall.packages(\"RColorBrewer\")\n\nInstalling package into '/home/runner/work/_temp/Library'\n(as 'lib' is unspecified)\n\nlibrary(RColorBrewer)\n\n\nset.seed(2020)\nmdim.sim.thetas &lt;- matrix(rnorm(5000), ncol = 5)\n\nSince this will be a dichotomous model, we’ll generate a single column for thresholds.\n\nmdim.sim.thresholds &lt;- runif(10, -3, 3)\n\nOkay, let’s see what the Wright Map looks like for this.\n\nwrightMap(mdim.sim.thetas, mdim.sim.thresholds)\n\n\n\n\n\n\n\n\nThat doesn’t look right. Let’s adjust the proportion of the map’s parts.\n\nwrightMap(mdim.sim.thetas, mdim.sim.thresholds, item.prop = 0.5)\n\n\n\n\n\n\n\n\nLet’s change the dimensions names.\n\nwrightMap(mdim.sim.thetas, mdim.sim.thresholds, item.prop = 0.5,\n    dim.names = c(\"Algebra\", \"Calculus\", \"Trig\", \"Stats\", \"Arithmetic\"))\n\n\n\n\n\n\n\n\nAnd let’s give them some color.\n\nwrightMap(mdim.sim.thetas, mdim.sim.thresholds, item.prop = 0.5,\n    dim.names = c(\"Algebra\", \"Calculus\", \"Trig\", \"Stats\", \"Arithmetic\"),\n    dim.color = brewer.pal(5, \"Set1\"))\n\n\n\n\n\n\n\n\nAnd let’s associate the items with each dimension.\n\nwrightMap(mdim.sim.thetas, mdim.sim.thresholds, item.prop = 0.5,\n    dim.names = c(\"Algebra\", \"Calculus\", \"Trig\", \"Stats\", \"Arithmetic\"),\n    dim.color = brewer.pal(5, \"Set1\"), show.thr.lab = FALSE,\n    thr.sym.col.fg = rep(brewer.pal(5, \"Set1\"), each = 2),\n    thr.sym.col.bg = rep(brewer.pal(5, \"Set1\"), each = 2),\n    thr.sym.cex = 2, use.hist = FALSE)\n\nParameter 'use.hist' is deprecated. Please use 'person.side' parameter instead.\n\n\n\n\n\n\n\n\n\n\n\n\nAll right, let’s look at a Rating Scale Model. First, let’s generate three dimensions of person estimates.\n\nrsm.sim.thetas &lt;- data.frame(d1 = rnorm(1000, mean = -0.5, sd = 1), d2 = rnorm(1000, \n    mean = 0, sd = 1), d3 = rnorm(1000, mean = +0.5, sd = 1))\n\nNow let’s generate the thresholds for the polytomous items. We’ll make them a matrix where each row is an item and each column a level.\n\nitems.loc &lt;- sort(rnorm(10))\n\nrsm.sim.thresholds &lt;- data.frame(l1 = items.loc - 1, l2 = items.loc - 0.5,\n    l3 = items.loc + 0.5, l4 = items.loc + 1)\n\nrsm.sim.thresholds\n\n           l1          l2          l3         l4\n1  -3.2296856 -2.72968555 -1.72968555 -1.2296856\n2  -3.0559158 -2.55591580 -1.55591580 -1.0559158\n3  -2.6763974 -2.17639745 -1.17639745 -0.6763974\n4  -1.9108197 -1.41081970 -0.41081970  0.0891803\n5  -1.5635229 -1.06352291 -0.06352291  0.4364771\n6  -1.4238738 -0.92387385  0.07612615  0.5761262\n7  -0.6849163 -0.18491631  0.81508369  1.3150837\n8  -0.4913923  0.00860773  1.00860773  1.5086077\n9  -0.4736099  0.02639011  1.02639011  1.5263901\n10  1.2934064  1.79340639  2.79340639  3.2934064\n\n\nLet’s look at the Wright Map!\n\nwrightMap(rsm.sim.thetas, rsm.sim.thresholds)\n\n\n\n\n\n\n\n\nLet’s assign a color for each level.\n\nitemlevelcolors &lt;- matrix(rep(brewer.pal(4, \"Set1\"), 10), byrow = TRUE, ncol = 4)\n\nitemlevelcolors\n\n      [,1]      [,2]      [,3]      [,4]     \n [1,] \"#E41A1C\" \"#377EB8\" \"#4DAF4A\" \"#984EA3\"\n [2,] \"#E41A1C\" \"#377EB8\" \"#4DAF4A\" \"#984EA3\"\n [3,] \"#E41A1C\" \"#377EB8\" \"#4DAF4A\" \"#984EA3\"\n [4,] \"#E41A1C\" \"#377EB8\" \"#4DAF4A\" \"#984EA3\"\n [5,] \"#E41A1C\" \"#377EB8\" \"#4DAF4A\" \"#984EA3\"\n [6,] \"#E41A1C\" \"#377EB8\" \"#4DAF4A\" \"#984EA3\"\n [7,] \"#E41A1C\" \"#377EB8\" \"#4DAF4A\" \"#984EA3\"\n [8,] \"#E41A1C\" \"#377EB8\" \"#4DAF4A\" \"#984EA3\"\n [9,] \"#E41A1C\" \"#377EB8\" \"#4DAF4A\" \"#984EA3\"\n[10,] \"#E41A1C\" \"#377EB8\" \"#4DAF4A\" \"#984EA3\"\n\n\nAnd now make a Wright Map with them.\n\nwrightMap(rsm.sim.thetas, rsm.sim.thresholds, thr.sym.col.fg = itemlevelcolors,\n    thr.sym.col.bg = itemlevelcolors)\n\n\n\n\n\n\n\n\nBut we also want to indicate which dimension they belong to… with symbols.\n\nitemdimsymbols &lt;- matrix(c(rep(16, 12), rep(17, 12), rep(18, 16)),\n    byrow = TRUE, ncol = 4)\n\nitemdimsymbols\n\n      [,1] [,2] [,3] [,4]\n [1,]   16   16   16   16\n [2,]   16   16   16   16\n [3,]   16   16   16   16\n [4,]   17   17   17   17\n [5,]   17   17   17   17\n [6,]   17   17   17   17\n [7,]   18   18   18   18\n [8,]   18   18   18   18\n [9,]   18   18   18   18\n[10,]   18   18   18   18\n\n\n\nwrightMap(rsm.sim.thetas, rsm.sim.thresholds, show.thr.lab = FALSE,\n    thr.sym.col.fg = itemlevelcolors, thr.sym.col.bg = itemlevelcolors,\n    thr.sym.pch = itemdimsymbols, thr.sym.cex = 2)\n\n\n\n\n\n\n\n\nAdditionally, we may want to clearly indicate which item parameters are associated with each item. We can draw lines that connect all parameters connected to an item using the vertLines parameter.\n\nwrightMap(rsm.sim.thetas, rsm.sim.thresholds, show.thr.lab = FALSE,\n    thr.sym.col.fg = itemlevelcolors, thr.sym.col.bg = itemlevelcolors,\n    thr.sym.pch = itemdimsymbols, thr.sym.cex = 2, vertLines = TRUE)"
  },
  {
    "objectID": "website/tutorial05.html",
    "href": "website/tutorial05.html",
    "title": "WrightMap Tutorial - Part 5",
    "section": "",
    "text": "Version 1.2 of the WrightMap package allows you to directly access the functions used for drawing the person and item sides of the map in order to allow more flexible item person maps. The parts can be put together on the same plot using the split.screen function.\n\n\n\nLet’s start by installing the latest version of the package from CRAN.\n\ninstall.packages('WrightMap')\n\nInstalling package into '/home/runner/work/_temp/Library'\n(as 'lib' is unspecified)\n\nlibrary(WrightMap)\n\nAnd set up some item data.\n\nset.seed(2020)\nitems.loc &lt;- sort( rnorm( 20))\nthresholds &lt;- data.frame(\n    l1 = items.loc - 0.5 ,\n    l2 = items.loc - 0.25,\n    l3 = items.loc + 0.25,\n    l4 = items.loc + 0.5)\n\nWe can draw a simple item map by calling one of the item side functions. Currently there are three: itemModern, itemClassic, and itemHist.\nThe itemModern function is the default called by wrightMap.\n\nitemModern(thresholds)\n\n\n\n\n\n\n\n\nThe itemClassic function creates item sides inspired by text-based Wright Maps.\n\nitemClassic(thresholds)\n\n\n\n\n\n\n\n\nFinally, the itemHist function plots the items as a histogram.\n\nitemHist(thresholds)\n\n\n\n\n\n\n\n\nSimilarly, the person side functions allow you to graph the person parameters. There are two: personHist and personDens.\n\n## Mock results\nmulti.proficiency &lt;- data.frame(\n    d1 = rnorm(1000, mean =  -0.5, sd = .5),\n    d2 = rnorm(1000, mean =   0.0, sd = 1),\n    d3 = rnorm(1000, mean =  +0.5, sd = 1),\n    d4 = rnorm(1000, mean =   0.0, sd = .5),\n    d5 = rnorm(1000, mean =  -0.5, sd = .75))\n\n\npersonHist(multi.proficiency)\n\n\n\n\n\n\n\n\n\npersonDens(multi.proficiency)\n\n\n\n\n\n\n\n\nTo use these plots in a Wright Map, use the item.side and person.side parameters.\n\nwrightMap(multi.proficiency, thresholds, item.side = itemClassic, item.prop = 0.5, person.side = personDens)\n\n\n\n\n\n\n\n\n\n\n\nThe person side and item side functions expect data in the form of matrices. They do not recognize CQmodel objects. When a CQModel object is sent to wrightMap, it first extracts the necessary data, and then sends the data to the plotting functions. In version 1.2, the data processing functions have also been made directly accessible to users in the form of the personData and itemData functions. These are fast ways to pull the data out of a CQmodel object in such a way that it is ready to be sent to wrightMap or any of the item and person plotting functions.\nThe personData function is very simple. It can take either a CQmodel object or a string containing the name of a ConQuest person parameter file. It extracts the person estimates as a matrix.\n\nfpath &lt;- system.file(\"extdata\", package=\"WrightMap\")\nmodel1 &lt;- CQmodel(file.path(fpath, \"ex7a.eap\"), file.path(fpath, \"ex7a.shw\"))\n\nm1.person &lt;- personData(model1)\n\n\npersonHist(m1.person, dim.lab.side = 1)\n\n\n\n\n\n\n\n\nThe itemData function uses the GIN table (Thurstonian thresholds) if it is present, and otherwise tries to create delta parameters out of the RMP tables. You can also specify tables to use as items, steps, and interactions, and it will add them together appropriately to create delta parameters.\n\nmodel2 &lt;- CQmodel(file.path(fpath, \"ex4a.mle\"), file.path(fpath, \"ex4a.shw\"))\nm2.item &lt;- itemData(model2, item.table = \"topic\", interactions = \"rater*topic\", step.table = \"rater\")\n\n\nitemModern(m2.item)\n\n\n\n\n\n\n\n\nHaving these data functions pulled out also makes it easier to combine parameters from different models onto a single plot (when appropriate).\n\nwrightMap(m1.person, m2.item)\n\n\n\n\n\n\n\n\n\n\n\nBy calling these functions directly and using split.screen, we can make Wright Maps with other arrangements of persons and items. The item side functions can be combined using any of the base graphics options for combining plots (layout, par(mfrow)), but the person side functions are based on split.screen, which is incompatible with those options. We will be combining item and person maps, so we need to use split.screen.\nThe first step of combining these functions is to set up the screens. Details for screen functions are in the documentation for split.screen. The function takes as a parameter a 4-column matrix, in which each row is a screen, and the columns represent the left, bottom, right, and top of the screens respectively. Each value is expressed as a number from 0 to 1, where 0 is the left/bottom of the current device and 1 is the right/top.\nTo make a Wright Map with the items on the left and the persons on the right, we will set up two screens, with 80% of the width on the left and 20% on the right.\n\nsplit.screen(figs = matrix(c(0, .8, 0, 1, .8, 1, 0, 1), ncol = 4, byrow = TRUE))\n\nNext, we’ll draw the item side. IMPORTANT NOTE: Make sure to explicitly set the yRange variable when combining plots to ensure they are on the same scale. We can also adjust some of the other parameters to work better with a left-side item plot. We’ll move the logit axis to the left with the show.axis.logit parameter, and set the righthand outer margin to 2 to give us a space between the plots.\n\nitemModern(thresholds, yRange = c(-3, 4), show.axis.logits = \"L\", oma = c(0, 0, 0, 2))\n\nmtext(\"Wright Map\", side = 3, font = 2, line = 1)\n\n\n\n\n\n\n\n\nFinally, we will move to screen 2 and draw the person side. This plot will be adjusted to move the persons label and remove the axis.\nscreen(2)\npersonHist(multi.proficiency, axis.persons = \"\", yRange = c(-3, 4), axis.logits = \"Persons\", show.axis.logits = FALSE)\n\n\n\n\n\n\n\n\n\nThe last thing to do is to close all the screens to prevent them from getting in the way of any future plotting.\n\nclose.screen(all.screens = TRUE)\n\nHere is the complete plot:\n\nsplit.screen(figs = matrix(c(0, .8, 0, 1, .8, 1, 0, 1), ncol = 4, byrow = TRUE))\n\nitemModern(thresholds, yRange = c(-3, 4), show.axis.logits = \"L\", oma = c(0, 0, 0, 2))\nmtext(\"Wright Map\", side = 3, font = 2, line = 1)\n\nscreen(2)\npersonHist(multi.proficiency, axis.persons = \"\", yRange = c(-3, 4), axis.logits = \"Persons\", show.axis.logits = FALSE)\n\nclose.screen(all.screens = TRUE)\n\n\n\n\n\n\n\n\nCountless arrangements are possible. As one last example, here are two ways to put two dimensions side by side in separate Wright Maps.\nExplicitly splitting the device into four screens:\n\nd1 = rnorm(1000, mean =  -0.5, sd = 1)\nd2 = rnorm(1000, mean =   0.0, sd = 1)\n\ndim1.diff &lt;- rnorm(5)\ndim2.diff &lt;- rnorm(5)\n\nsplit.screen(figs = matrix(c(  0, .09, 0, 1,\n                             .11, .58, 0, 1,\n                              .5, .59, 0, 1,\n                             .51,  1, 0, 1), ncol = 4, byrow = TRUE))\n                            \n    personDens(d1, yRange = c(-3, 3), show.axis.logits = FALSE, axis.logits = \"\")\n\nscreen(2)\n    itemModern(dim1.diff, yRange = c(-3, 3), show.axis.logits = FALSE)\n    mtext(\"Wright Map\", side = 3, font = 2, line = 1)\n\nscreen(3)\n    personDens(d2, yRange = c(-3, 3), show.axis.logits = FALSE, axis.logits = \"\", axis.persons = \"\", dim.names = \"Dim2\")\n\nscreen(4)\n    itemModern(dim2.diff, yRange = c(-3, 3), show.axis.logits = FALSE, label.items = paste(\"Item\", 6:10))\n\n\n\n\n\n\n\nclose.screen(all.screens = TRUE)\n\nSplitting the device into two screens with a Wright Map on each:\n\nsplit.screen(figs = matrix(c( 0, .5, 0, 1,\n                             .5, 1, 0, 1), ncol = 4, byrow = TRUE))\n                              \nwrightMap(d1, dim1.diff, person.side = personDens, show.axis.logits = FALSE)\n\nscreen(2)\nwrightMap(d2, dim2.diff, person.side = personDens, show.axis.logits = FALSE)\n\nclose.screen(all.screens = TRUE)"
  },
  {
    "objectID": "website/tutorial05.html#more-flexibility-using-the-person-and-item-side-functions",
    "href": "website/tutorial05.html#more-flexibility-using-the-person-and-item-side-functions",
    "title": "WrightMap Tutorial - Part 5",
    "section": "",
    "text": "Version 1.2 of the WrightMap package allows you to directly access the functions used for drawing the person and item sides of the map in order to allow more flexible item person maps. The parts can be put together on the same plot using the split.screen function.\n\n\n\nLet’s start by installing the latest version of the package from CRAN.\n\ninstall.packages('WrightMap')\n\nInstalling package into '/home/runner/work/_temp/Library'\n(as 'lib' is unspecified)\n\nlibrary(WrightMap)\n\nAnd set up some item data.\n\nset.seed(2020)\nitems.loc &lt;- sort( rnorm( 20))\nthresholds &lt;- data.frame(\n    l1 = items.loc - 0.5 ,\n    l2 = items.loc - 0.25,\n    l3 = items.loc + 0.25,\n    l4 = items.loc + 0.5)\n\nWe can draw a simple item map by calling one of the item side functions. Currently there are three: itemModern, itemClassic, and itemHist.\nThe itemModern function is the default called by wrightMap.\n\nitemModern(thresholds)\n\n\n\n\n\n\n\n\nThe itemClassic function creates item sides inspired by text-based Wright Maps.\n\nitemClassic(thresholds)\n\n\n\n\n\n\n\n\nFinally, the itemHist function plots the items as a histogram.\n\nitemHist(thresholds)\n\n\n\n\n\n\n\n\nSimilarly, the person side functions allow you to graph the person parameters. There are two: personHist and personDens.\n\n## Mock results\nmulti.proficiency &lt;- data.frame(\n    d1 = rnorm(1000, mean =  -0.5, sd = .5),\n    d2 = rnorm(1000, mean =   0.0, sd = 1),\n    d3 = rnorm(1000, mean =  +0.5, sd = 1),\n    d4 = rnorm(1000, mean =   0.0, sd = .5),\n    d5 = rnorm(1000, mean =  -0.5, sd = .75))\n\n\npersonHist(multi.proficiency)\n\n\n\n\n\n\n\n\n\npersonDens(multi.proficiency)\n\n\n\n\n\n\n\n\nTo use these plots in a Wright Map, use the item.side and person.side parameters.\n\nwrightMap(multi.proficiency, thresholds, item.side = itemClassic, item.prop = 0.5, person.side = personDens)\n\n\n\n\n\n\n\n\n\n\n\nThe person side and item side functions expect data in the form of matrices. They do not recognize CQmodel objects. When a CQModel object is sent to wrightMap, it first extracts the necessary data, and then sends the data to the plotting functions. In version 1.2, the data processing functions have also been made directly accessible to users in the form of the personData and itemData functions. These are fast ways to pull the data out of a CQmodel object in such a way that it is ready to be sent to wrightMap or any of the item and person plotting functions.\nThe personData function is very simple. It can take either a CQmodel object or a string containing the name of a ConQuest person parameter file. It extracts the person estimates as a matrix.\n\nfpath &lt;- system.file(\"extdata\", package=\"WrightMap\")\nmodel1 &lt;- CQmodel(file.path(fpath, \"ex7a.eap\"), file.path(fpath, \"ex7a.shw\"))\n\nm1.person &lt;- personData(model1)\n\n\npersonHist(m1.person, dim.lab.side = 1)\n\n\n\n\n\n\n\n\nThe itemData function uses the GIN table (Thurstonian thresholds) if it is present, and otherwise tries to create delta parameters out of the RMP tables. You can also specify tables to use as items, steps, and interactions, and it will add them together appropriately to create delta parameters.\n\nmodel2 &lt;- CQmodel(file.path(fpath, \"ex4a.mle\"), file.path(fpath, \"ex4a.shw\"))\nm2.item &lt;- itemData(model2, item.table = \"topic\", interactions = \"rater*topic\", step.table = \"rater\")\n\n\nitemModern(m2.item)\n\n\n\n\n\n\n\n\nHaving these data functions pulled out also makes it easier to combine parameters from different models onto a single plot (when appropriate).\n\nwrightMap(m1.person, m2.item)\n\n\n\n\n\n\n\n\n\n\n\nBy calling these functions directly and using split.screen, we can make Wright Maps with other arrangements of persons and items. The item side functions can be combined using any of the base graphics options for combining plots (layout, par(mfrow)), but the person side functions are based on split.screen, which is incompatible with those options. We will be combining item and person maps, so we need to use split.screen.\nThe first step of combining these functions is to set up the screens. Details for screen functions are in the documentation for split.screen. The function takes as a parameter a 4-column matrix, in which each row is a screen, and the columns represent the left, bottom, right, and top of the screens respectively. Each value is expressed as a number from 0 to 1, where 0 is the left/bottom of the current device and 1 is the right/top.\nTo make a Wright Map with the items on the left and the persons on the right, we will set up two screens, with 80% of the width on the left and 20% on the right.\n\nsplit.screen(figs = matrix(c(0, .8, 0, 1, .8, 1, 0, 1), ncol = 4, byrow = TRUE))\n\nNext, we’ll draw the item side. IMPORTANT NOTE: Make sure to explicitly set the yRange variable when combining plots to ensure they are on the same scale. We can also adjust some of the other parameters to work better with a left-side item plot. We’ll move the logit axis to the left with the show.axis.logit parameter, and set the righthand outer margin to 2 to give us a space between the plots.\n\nitemModern(thresholds, yRange = c(-3, 4), show.axis.logits = \"L\", oma = c(0, 0, 0, 2))\n\nmtext(\"Wright Map\", side = 3, font = 2, line = 1)\n\n\n\n\n\n\n\n\nFinally, we will move to screen 2 and draw the person side. This plot will be adjusted to move the persons label and remove the axis.\nscreen(2)\npersonHist(multi.proficiency, axis.persons = \"\", yRange = c(-3, 4), axis.logits = \"Persons\", show.axis.logits = FALSE)\n\n\n\n\n\n\n\n\n\nThe last thing to do is to close all the screens to prevent them from getting in the way of any future plotting.\n\nclose.screen(all.screens = TRUE)\n\nHere is the complete plot:\n\nsplit.screen(figs = matrix(c(0, .8, 0, 1, .8, 1, 0, 1), ncol = 4, byrow = TRUE))\n\nitemModern(thresholds, yRange = c(-3, 4), show.axis.logits = \"L\", oma = c(0, 0, 0, 2))\nmtext(\"Wright Map\", side = 3, font = 2, line = 1)\n\nscreen(2)\npersonHist(multi.proficiency, axis.persons = \"\", yRange = c(-3, 4), axis.logits = \"Persons\", show.axis.logits = FALSE)\n\nclose.screen(all.screens = TRUE)\n\n\n\n\n\n\n\n\nCountless arrangements are possible. As one last example, here are two ways to put two dimensions side by side in separate Wright Maps.\nExplicitly splitting the device into four screens:\n\nd1 = rnorm(1000, mean =  -0.5, sd = 1)\nd2 = rnorm(1000, mean =   0.0, sd = 1)\n\ndim1.diff &lt;- rnorm(5)\ndim2.diff &lt;- rnorm(5)\n\nsplit.screen(figs = matrix(c(  0, .09, 0, 1,\n                             .11, .58, 0, 1,\n                              .5, .59, 0, 1,\n                             .51,  1, 0, 1), ncol = 4, byrow = TRUE))\n                            \n    personDens(d1, yRange = c(-3, 3), show.axis.logits = FALSE, axis.logits = \"\")\n\nscreen(2)\n    itemModern(dim1.diff, yRange = c(-3, 3), show.axis.logits = FALSE)\n    mtext(\"Wright Map\", side = 3, font = 2, line = 1)\n\nscreen(3)\n    personDens(d2, yRange = c(-3, 3), show.axis.logits = FALSE, axis.logits = \"\", axis.persons = \"\", dim.names = \"Dim2\")\n\nscreen(4)\n    itemModern(dim2.diff, yRange = c(-3, 3), show.axis.logits = FALSE, label.items = paste(\"Item\", 6:10))\n\n\n\n\n\n\n\nclose.screen(all.screens = TRUE)\n\nSplitting the device into two screens with a Wright Map on each:\n\nsplit.screen(figs = matrix(c( 0, .5, 0, 1,\n                             .5, 1, 0, 1), ncol = 4, byrow = TRUE))\n                              \nwrightMap(d1, dim1.diff, person.side = personDens, show.axis.logits = FALSE)\n\nscreen(2)\nwrightMap(d2, dim2.diff, person.side = personDens, show.axis.logits = FALSE)\n\nclose.screen(all.screens = TRUE)"
  },
  {
    "objectID": "website/tutorial02.html",
    "href": "website/tutorial02.html",
    "title": "WrightMap Tutorial - Part 2",
    "section": "",
    "text": "We start by creating mock person and item estimates.\nFor the person proficiencies, we create a matrix with 1000 values per dimension (5 dimensions in total).\n\nset.seed(2020)\nmdim.sim.thetas &lt;- matrix(rnorm(5000), ncol = 5)\n\n\n\n\nWhat happens if you have too many items?\n\nrasch2.sim.thresholds &lt;- runif(50, -3, 3)\n\nIf we use the defaults…\n\nwrightMap(rnorm(1000), rasch2.sim.thresholds)\n\n\n\n\n\n\n\n\nThings do not look quite right.\nWrightMap offers some options…\n\nrasch.sim.thetas &lt;- rnorm(1000)\nrasch2.sim.thresholds &lt;- runif(10, -3, 3)\n\nYou can use the itemClassic or itemHist options for item.side.\n\nwrightMap(rasch.sim.thetas, rasch2.sim.thresholds, item.side = itemClassic, item.prop = .5)\n\n\n\n\n\n\n\n\n\nwrightMap(rasch.sim.thetas, rasch2.sim.thresholds, item.side = itemHist, item.prop = 0.5)\n\n\n\n\n\n\n\n\nOr you can play with the way labels are presented:\n\nwrightMap(rnorm(1000), rasch2.sim.thresholds, show.thr.lab = FALSE, label.items.srt = 45)\n\n\n\n\n\n\n\n\n\nwrightMap(rnorm(1000), rasch2.sim.thresholds, show.thr.lab = FALSE, label.items.rows = 2)\n\n\n\n\n\n\n\n\n\nwrightMap(rnorm(1000), rasch2.sim.thresholds, show.thr.lab = FALSE, label.items = c(1:50), label.items.rows = 3)\n\n\n\n\n\n\n\n\nOr you can get rid of that axis completely.\n\nwrightMap(rnorm(1000), rasch2.sim.thresholds, show.thr.sym = FALSE,\n    thr.lab.text = paste(\"I\", 1:10, sep = \"\"), label.items = \"\", label.items.ticks = FALSE)"
  },
  {
    "objectID": "website/tutorial02.html#plotting-the-items-in-different-ways",
    "href": "website/tutorial02.html#plotting-the-items-in-different-ways",
    "title": "WrightMap Tutorial - Part 2",
    "section": "",
    "text": "We start by creating mock person and item estimates.\nFor the person proficiencies, we create a matrix with 1000 values per dimension (5 dimensions in total).\n\nset.seed(2020)\nmdim.sim.thetas &lt;- matrix(rnorm(5000), ncol = 5)\n\n\n\n\nWhat happens if you have too many items?\n\nrasch2.sim.thresholds &lt;- runif(50, -3, 3)\n\nIf we use the defaults…\n\nwrightMap(rnorm(1000), rasch2.sim.thresholds)\n\n\n\n\n\n\n\n\nThings do not look quite right.\nWrightMap offers some options…\n\nrasch.sim.thetas &lt;- rnorm(1000)\nrasch2.sim.thresholds &lt;- runif(10, -3, 3)\n\nYou can use the itemClassic or itemHist options for item.side.\n\nwrightMap(rasch.sim.thetas, rasch2.sim.thresholds, item.side = itemClassic, item.prop = .5)\n\n\n\n\n\n\n\n\n\nwrightMap(rasch.sim.thetas, rasch2.sim.thresholds, item.side = itemHist, item.prop = 0.5)\n\n\n\n\n\n\n\n\nOr you can play with the way labels are presented:\n\nwrightMap(rnorm(1000), rasch2.sim.thresholds, show.thr.lab = FALSE, label.items.srt = 45)\n\n\n\n\n\n\n\n\n\nwrightMap(rnorm(1000), rasch2.sim.thresholds, show.thr.lab = FALSE, label.items.rows = 2)\n\n\n\n\n\n\n\n\n\nwrightMap(rnorm(1000), rasch2.sim.thresholds, show.thr.lab = FALSE, label.items = c(1:50), label.items.rows = 3)\n\n\n\n\n\n\n\n\nOr you can get rid of that axis completely.\n\nwrightMap(rnorm(1000), rasch2.sim.thresholds, show.thr.sym = FALSE,\n    thr.lab.text = paste(\"I\", 1:10, sep = \"\"), label.items = \"\", label.items.ticks = FALSE)"
  },
  {
    "objectID": "website/index.html",
    "href": "website/index.html",
    "title": "WrightMap",
    "section": "",
    "text": "Wright Maps are commonly used to present the results of dichotomous or polytomous item response models. The WrightMap package provides functions to easily create these beautiful Wright Maps from item parameters and person estimates stored as R objects.\n\n\n\n\n\n\n\n\n\nYou can read more about WrightMaps, browse our tutorials, or review our examples."
  },
  {
    "objectID": "website/index.html#welcome-to-the-official-home-of-the-wrightmap-package",
    "href": "website/index.html#welcome-to-the-official-home-of-the-wrightmap-package",
    "title": "WrightMap",
    "section": "",
    "text": "Wright Maps are commonly used to present the results of dichotomous or polytomous item response models. The WrightMap package provides functions to easily create these beautiful Wright Maps from item parameters and person estimates stored as R objects.\n\n\n\n\n\n\n\n\n\nYou can read more about WrightMaps, browse our tutorials, or review our examples."
  },
  {
    "objectID": "website/tutorial01.html",
    "href": "website/tutorial01.html",
    "title": "WrightMap Tutorial - Part 1",
    "section": "",
    "text": "This is an introduction to the wrightMap function in the WrightMap package. The wrightMap function creates Wright Maps based on person estimates and item parameters produced by an item response analysis. The CQmodel function reads output files created using ConQuest software and creates a set of data frames for easy data manipulation, bundled in a CQmodel object. The wrightMap function can take a CQmodel object as input or it can be used to create Wright Maps directly from data frames of person and item parameters.\n\n\n\nLet’s start by installing the latest version of the package from CRAN.\n\nlibrary(WrightMap)\n\nWe will also load RColorBrewer to take advantage of its color palettes.\n\nlibrary(RColorBrewer)\n\n\n\n\nTo plot a simple Rasch model, we start by creating mock person and item estimates.\nFor the person proficiencies, we create a single vector with 1000 values.\n\nset.seed(2020)\nrasch.sim.thetas &lt;- rnorm(1000)\n\nAnd for the item difficulties, we create a vector with 10 values.\n\nrasch.sim.thresholds &lt;- runif(10, -3, 3)\n\nWe now have all we need to create a WrightMap with a single line.\n\nwrightMap(rasch.sim.thetas, rasch.sim.thresholds)\n\n\n\n\n\n\n\n\nWe can start to customize the Wright Map by simply relabeling its main parts using main.title, axis.logits, axis.persons, and axis.items.\n\nwrightMap(rasch.sim.thetas, rasch.sim.thresholds,\n    main.title = \"This is my example Wright Map\",\n    axis.persons = \"This is the person distribution\",\n    axis.items = \"These are my survey questions\")\n\n\n\n\n\n\n\n\n\n\n\nIf you do not like histograms, WrightMap has the option person.side that allows you to switch between histograms (the default option: personHist) or density using the option personDens.\n\nwrightMap(rasch.sim.thetas, rasch.sim.thresholds, person.side = personDens)\n\n\n\n\n\n\n\n\nOr, you may want to change the way items are represented by using the option item.side, which offers itemModern (the default representation), itemClassic (for ConQuest-style Wright Maps), and a itemHist for a histogram summary of the items.\nThe itemClassic option is well suited for cases where you want to include many items using less space.\n\nrasch.sim.thresholds.2 &lt;- runif(150, -3, 3)\nwrightMap(rasch.sim.thetas, rasch.sim.thresholds.2, item.side = itemClassic)\n\n\n\n\n\n\n\n\nAlternatively, you can represent use a back-to-back histogram representation with itemHist (notice that in the following example we are using the option item.prop to adjust the relative sizes of the person and item side).\n\nrasch.sim.thresholds.3 &lt;- rnorm(150)\nwrightMap(rasch.sim.thetas, rasch.sim.thresholds.2, item.side = itemHist, item.prop = 0.5)\n\n\n\n\n\n\n\n\n\n\n\nLet us focus on the default item and person side representations to explore their potential customizations.\nYou might want to remove the label for the item difficulties by setting show.thr.lab = FALSE.\n\nwrightMap(rasch.sim.thetas, rasch.sim.thresholds, show.thr.lab = FALSE)\n\n\n\n\n\n\n\n\nOr you might want to see just labels, by turning off symbols with show.thr.sym = FALSE.\n\nwrightMap(rasch.sim.thetas, rasch.sim.thresholds, show.thr.sym = FALSE)\n\n\n\n\n\n\n\n\n\n\n\nLet’s start by making all the symbols bigger with thr.sym.cex = 2.5 (default is 1).\n\nwrightMap(rasch.sim.thetas, rasch.sim.thresholds,\n    show.thr.lab = FALSE, thr.sym.cex = 2.5)\n\n\n\n\n\n\n\n\nTo select what kind of symbols you want to use, you can use the thr.sym.pch parameter.\n\nwrightMap(rasch.sim.thetas, rasch.sim.thresholds, show.thr.lab = FALSE,\n    thr.sym.cex = 2.5, thr.sym.pch = 17)\n\n\n\n\n\n\n\n\n\n\n\nWe will need some colors for the next examples.\n\ndisplay.brewer.pal(10, \"Paired\")\n\n\n\n\n\n\n\nitemcolors &lt;- brewer.pal(10, \"Paired\")\n\nNow, let’s use those colors in our item difficulty symbols using the thr.sym.col.fg.\n\nwrightMap(rasch.sim.thetas, rasch.sim.thresholds, show.thr.lab = FALSE,\n    thr.sym.pch = 17, thr.sym.cex = 2.5, thr.sym.col.fg = itemcolors)\n\n\n\n\n\n\n\n\n\n\n\nDefine some item names:\n\nitemnames &lt;- c(\"Dasher\", \"Dancer\", \"Prancer\", \"Vixen\", \"Comet\", \"Cupid\", \"Donner\", \n    \"Blitzen\", \"Rudolph\", \"Olive\")\n\nNow assign them to the item difficulties:\n\nwrightMap(rasch.sim.thetas, rasch.sim.thresholds, show.thr.sym = FALSE,\n    thr.lab.text = itemnames)\n\n\n\n\n\n\n\n\nYou can also control the size of the labels using the thr.lab.cex parameter.\n\nwrightMap(rasch.sim.thetas, rasch.sim.thresholds, show.thr.sym = FALSE,\n    thr.lab.text = itemnames, thr.lab.cex = 1.5)\n\n\n\n\n\n\n\n\nAnd we can of course control the colors using thr.lab.col.\n\nwrightMap(rasch.sim.thetas, rasch.sim.thresholds, show.thr.sym = FALSE,\n    thr.lab.text = itemnames, thr.lab.col = itemcolors, thr.lab.cex = 1.5)\n\n\n\n\n\n\n\n\nFinally, if you want to go crazy, you can also change the type style using thr.lab.font. This parameter follows the R convention where 1 = plain, 2 = bold, 3 = italic, 4 = bold italic.\n\nwrightMap(rasch.sim.thetas, rasch.sim.thresholds, show.thr.sym = FALSE,\n    thr.lab.text = itemnames, thr.lab.col = itemcolors,\n    thr.lab.cex = 1.5, thr.lab.font = c(1:4))"
  },
  {
    "objectID": "website/tutorial01.html#plotting-unidimensionaldichotomous-models",
    "href": "website/tutorial01.html#plotting-unidimensionaldichotomous-models",
    "title": "WrightMap Tutorial - Part 1",
    "section": "",
    "text": "This is an introduction to the wrightMap function in the WrightMap package. The wrightMap function creates Wright Maps based on person estimates and item parameters produced by an item response analysis. The CQmodel function reads output files created using ConQuest software and creates a set of data frames for easy data manipulation, bundled in a CQmodel object. The wrightMap function can take a CQmodel object as input or it can be used to create Wright Maps directly from data frames of person and item parameters.\n\n\n\nLet’s start by installing the latest version of the package from CRAN.\n\nlibrary(WrightMap)\n\nWe will also load RColorBrewer to take advantage of its color palettes.\n\nlibrary(RColorBrewer)\n\n\n\n\nTo plot a simple Rasch model, we start by creating mock person and item estimates.\nFor the person proficiencies, we create a single vector with 1000 values.\n\nset.seed(2020)\nrasch.sim.thetas &lt;- rnorm(1000)\n\nAnd for the item difficulties, we create a vector with 10 values.\n\nrasch.sim.thresholds &lt;- runif(10, -3, 3)\n\nWe now have all we need to create a WrightMap with a single line.\n\nwrightMap(rasch.sim.thetas, rasch.sim.thresholds)\n\n\n\n\n\n\n\n\nWe can start to customize the Wright Map by simply relabeling its main parts using main.title, axis.logits, axis.persons, and axis.items.\n\nwrightMap(rasch.sim.thetas, rasch.sim.thresholds,\n    main.title = \"This is my example Wright Map\",\n    axis.persons = \"This is the person distribution\",\n    axis.items = \"These are my survey questions\")\n\n\n\n\n\n\n\n\n\n\n\nIf you do not like histograms, WrightMap has the option person.side that allows you to switch between histograms (the default option: personHist) or density using the option personDens.\n\nwrightMap(rasch.sim.thetas, rasch.sim.thresholds, person.side = personDens)\n\n\n\n\n\n\n\n\nOr, you may want to change the way items are represented by using the option item.side, which offers itemModern (the default representation), itemClassic (for ConQuest-style Wright Maps), and a itemHist for a histogram summary of the items.\nThe itemClassic option is well suited for cases where you want to include many items using less space.\n\nrasch.sim.thresholds.2 &lt;- runif(150, -3, 3)\nwrightMap(rasch.sim.thetas, rasch.sim.thresholds.2, item.side = itemClassic)\n\n\n\n\n\n\n\n\nAlternatively, you can represent use a back-to-back histogram representation with itemHist (notice that in the following example we are using the option item.prop to adjust the relative sizes of the person and item side).\n\nrasch.sim.thresholds.3 &lt;- rnorm(150)\nwrightMap(rasch.sim.thetas, rasch.sim.thresholds.2, item.side = itemHist, item.prop = 0.5)\n\n\n\n\n\n\n\n\n\n\n\nLet us focus on the default item and person side representations to explore their potential customizations.\nYou might want to remove the label for the item difficulties by setting show.thr.lab = FALSE.\n\nwrightMap(rasch.sim.thetas, rasch.sim.thresholds, show.thr.lab = FALSE)\n\n\n\n\n\n\n\n\nOr you might want to see just labels, by turning off symbols with show.thr.sym = FALSE.\n\nwrightMap(rasch.sim.thetas, rasch.sim.thresholds, show.thr.sym = FALSE)\n\n\n\n\n\n\n\n\n\n\n\nLet’s start by making all the symbols bigger with thr.sym.cex = 2.5 (default is 1).\n\nwrightMap(rasch.sim.thetas, rasch.sim.thresholds,\n    show.thr.lab = FALSE, thr.sym.cex = 2.5)\n\n\n\n\n\n\n\n\nTo select what kind of symbols you want to use, you can use the thr.sym.pch parameter.\n\nwrightMap(rasch.sim.thetas, rasch.sim.thresholds, show.thr.lab = FALSE,\n    thr.sym.cex = 2.5, thr.sym.pch = 17)\n\n\n\n\n\n\n\n\n\n\n\nWe will need some colors for the next examples.\n\ndisplay.brewer.pal(10, \"Paired\")\n\n\n\n\n\n\n\nitemcolors &lt;- brewer.pal(10, \"Paired\")\n\nNow, let’s use those colors in our item difficulty symbols using the thr.sym.col.fg.\n\nwrightMap(rasch.sim.thetas, rasch.sim.thresholds, show.thr.lab = FALSE,\n    thr.sym.pch = 17, thr.sym.cex = 2.5, thr.sym.col.fg = itemcolors)\n\n\n\n\n\n\n\n\n\n\n\nDefine some item names:\n\nitemnames &lt;- c(\"Dasher\", \"Dancer\", \"Prancer\", \"Vixen\", \"Comet\", \"Cupid\", \"Donner\", \n    \"Blitzen\", \"Rudolph\", \"Olive\")\n\nNow assign them to the item difficulties:\n\nwrightMap(rasch.sim.thetas, rasch.sim.thresholds, show.thr.sym = FALSE,\n    thr.lab.text = itemnames)\n\n\n\n\n\n\n\n\nYou can also control the size of the labels using the thr.lab.cex parameter.\n\nwrightMap(rasch.sim.thetas, rasch.sim.thresholds, show.thr.sym = FALSE,\n    thr.lab.text = itemnames, thr.lab.cex = 1.5)\n\n\n\n\n\n\n\n\nAnd we can of course control the colors using thr.lab.col.\n\nwrightMap(rasch.sim.thetas, rasch.sim.thresholds, show.thr.sym = FALSE,\n    thr.lab.text = itemnames, thr.lab.col = itemcolors, thr.lab.cex = 1.5)\n\n\n\n\n\n\n\n\nFinally, if you want to go crazy, you can also change the type style using thr.lab.font. This parameter follows the R convention where 1 = plain, 2 = bold, 3 = italic, 4 = bold italic.\n\nwrightMap(rasch.sim.thetas, rasch.sim.thresholds, show.thr.sym = FALSE,\n    thr.lab.text = itemnames, thr.lab.col = itemcolors,\n    thr.lab.cex = 1.5, thr.lab.font = c(1:4))"
  },
  {
    "objectID": "website/example03.html",
    "href": "website/example03.html",
    "title": "Introducing Person Probability Plots",
    "section": "",
    "text": "In this tutorial, we’re going to dive into a cool new feature introduced in WrightMap version 1.2: the Person Probability Plot (PP plot). This plot is designed to represent model information for specific proficiencies, giving us a neat way to visualize the uncertainty surrounding a person’s estimate and to see the probabilities that the person will answer different items correctly.\nLet’s get started by loading an example ConQuest output:\n\nfpath &lt;- system.file(\"extdata\", package=\"WrightMap\")\nmodel1 &lt;- CQmodel(p.est = file.path(fpath,\"ex2.eap\"), show = file.path(fpath,\"ex2.shw\"))"
  },
  {
    "objectID": "website/example03.html#introduction",
    "href": "website/example03.html#introduction",
    "title": "Introducing Person Probability Plots",
    "section": "",
    "text": "In this tutorial, we’re going to dive into a cool new feature introduced in WrightMap version 1.2: the Person Probability Plot (PP plot). This plot is designed to represent model information for specific proficiencies, giving us a neat way to visualize the uncertainty surrounding a person’s estimate and to see the probabilities that the person will answer different items correctly.\nLet’s get started by loading an example ConQuest output:\n\nfpath &lt;- system.file(\"extdata\", package=\"WrightMap\")\nmodel1 &lt;- CQmodel(p.est = file.path(fpath,\"ex2.eap\"), show = file.path(fpath,\"ex2.shw\"))"
  },
  {
    "objectID": "website/example03.html#creating-a-basic-person-probability-plot",
    "href": "website/example03.html#creating-a-basic-person-probability-plot",
    "title": "Introducing Person Probability Plots",
    "section": "Creating a Basic Person Probability Plot",
    "text": "Creating a Basic Person Probability Plot\nNow, let’s create the default version of the PP plot. There are three key things we need to provide:\n\nA model object (in this case, model1 from ConQuest)\nThe person’s proficiency estimate (let’s set it at 0 logits)\nThe standard error associated with the estimate (we’ll use 1 logit as the standard error)\n\nHere’s the code to generate the plot:\n\nppPlot(model1, est = 0, SE = 1)\n\nUsing GIN table for threshold parameters\n\n\n\n\n\nBasic Person Probability Plot\n\n\n\n\n\nUnderstanding the Plot\nIn this basic version, we’re using the ConQuest item and person information stored in model1. The person being represented has a proficiency estimate of 0 logits and a standard error of 1 logit.\n\nPerson Side (Histogram): The darkest bar represents the group in which the person’s proficiency estimate falls. The light gray bars on either side show the range of the standard error.\nItem Side (Probability Lines): For each item, the lines mark the probabilities that a person with this proficiency would answer correctly. The plot draws lines at 80%, 60%, 50%, 40%, and 20% probability thresholds."
  },
  {
    "objectID": "website/example03.html#modifying-the-plot-adding-density-and-classic-item-styles",
    "href": "website/example03.html#modifying-the-plot-adding-density-and-classic-item-styles",
    "title": "Introducing Person Probability Plots",
    "section": "Modifying the Plot: Adding Density and Classic Item Styles",
    "text": "Modifying the Plot: Adding Density and Classic Item Styles\nWhat if you want to change things up? Let’s try using a density plot on the person side instead of a histogram and switch to a classic style for the item side. Here’s how:\n\nppPlot(model1, est = 0, SE = 1, person.side = personDens, item.side = itemClassic)\n\nUsing GIN table for threshold parameters\n\n\n\n\n\nPerson Probability Plot with Density and Classic Item Style\n\n\n\n\nIn this version: - Person Side (Density): We’re using a density curve instead of the histogram to show where the proficiency estimate falls. - Item Side (Classic): We’re switching to a “classic” item representation, giving us a more traditional look for the probability lines."
  },
  {
    "objectID": "website/example03.html#conclusion",
    "href": "website/example03.html#conclusion",
    "title": "Introducing Person Probability Plots",
    "section": "Conclusion",
    "text": "Conclusion\nThe Person Probability Plot is a great tool for visualizing the relationship between person proficiencies and item difficulties, especially when you want to show how likely it is for a person to answer specific items correctly. You can easily customize these plots by switching between histogram or density views on the person side, and by using different styles for the item side.\nHopefully, this new addition to WrightMap will make it easier to communicate the results of a model for specific respondents. Play around with the options and see how the PP plot can enhance your analysis!"
  },
  {
    "objectID": "website/example02.html",
    "href": "website/example02.html",
    "title": "Using WrightMap with the TAM Package",
    "section": "",
    "text": "WrightMap features close integration with Conquest, allowing you to easily read from its output files. However, this is just a nice convenience for Conquest users, as WrightMap was designed to create beautiful item-person plots simply reading standard R matrices; all you need is a matrix of item parameters and a matrix of person estimates, and you can start creating nice Wright Maps. For this reason, the WrightMap package can be used to plot the results of any IRT software and makes it very easy to integrate with other R packages that estimate IRT models.\nThis post will show you how you can integrate R with one of these estimation packages, the Test Analysis Module (TAM) package, in just a couple of lines.\n\n\nLet’s start by loading TAM.\n\nlibrary(TAM)\n\nLoading required package: CDM\n\n\nLoading required package: mvtnorm\n\n\n**********************************\n** CDM 8.2-6 (2022-08-25 15:43:23)       \n** Cognitive Diagnostic Models  **\n**********************************\n\n\n* TAM 4.2-21 (2024-02-19 18:52:08)\n\n\nAnd we can use one of TAM’s simulated datasets (without any missing data in this case) for this example:\n\ndata(data.sim.rasch)\nstr(data.sim.rasch)\n\n num [1:2000, 1:40] 1 0 1 1 1 1 1 1 1 1 ...\n - attr(*, \"dimnames\")=List of 2\n  ..$ : NULL\n  ..$ : chr [1:40] \"I1\" \"I2\" \"I3\" \"I4\" ...\n\n\nA quick look with str confirms that we now have a simulated dataset with responses from 2000 persons (rows) to 40 items (columns). We are ready to go!\n\n\n\nIn this example, we will run a Rasch model using the TAM command tam.mml, which will estimate the model using a marginal maximum likelihood method.\n\nmod1 &lt;- tam.mml(resp=data.sim.rasch, verbose=FALSE)\n\nThe estimation should take very little time, and you should see a summary of the results and the total time it took to run the analysis.\n\n\n\nYou can get person estimates in several ways in TAM, but for this example, I will use the tam.wle command, which produces Warm Likelihood Estimates (WLE) for each respondent.\n\npersons.mod1 &lt;- tam.wle(mod1)\n\nIteration in WLE/MLE estimation  1   | Maximal change  0.8281 \nIteration in WLE/MLE estimation  2   | Maximal change  0.4335 \nIteration in WLE/MLE estimation  3   | Maximal change  0.0883 \nIteration in WLE/MLE estimation  4   | Maximal change  7e-04 \nIteration in WLE/MLE estimation  5   | Maximal change  0 \n----\n WLE Reliability= 0.894 \n\nstr(persons.mod1)\n\nClasses 'tam.wle' and 'data.frame': 2000 obs. of  7 variables:\n $ pid         : int  1 2 3 4 5 6 7 8 9 10 ...\n $ N.items     : num  40 40 40 40 40 40 40 40 40 40 ...\n $ PersonScores: num  19 14 35 14 27 12 23 17 5 12 ...\n $ PersonMax   : num  40 40 40 40 40 40 40 40 40 40 ...\n $ theta       : num  -0.116 -0.791 2.373 -0.791 0.964 ...\n $ error       : num  0.366 0.377 0.498 0.377 0.382 ...\n $ WLE.rel     : num  0.894 0.894 0.894 0.894 0.894 ...\n - attr(*, \"ndim\")= int 1\n - attr(*, \"nobs\")= int 2000\n - attr(*, \"M_sq_error\")= Named num 0.165\n  ..- attr(*, \"names\")= chr \"Dim1\"\n - attr(*, \"WLEvar\")= Named num 1.55\n  ..- attr(*, \"names\")= chr \"Dim1\"\n - attr(*, \"WLEM\")= Named num 0.000865\n  ..- attr(*, \"names\")= chr \"Dim1\"\n - attr(*, \"WLE.rel\")= num 0.894\n - attr(*, \"call\")= language tam.wle(tamobj = mod1)\n\n\nIf we look at the resulting matrix, we can see that we have several columns, including:\n\npid: the ID of the respondent\nN.items: the number of items\nPersonScores: The score of each person\nPersonMax: The maximum possible score of each person\ntheta: The WLE estimate\nerror: The standard error of the WLE estimate\nWLE.rel: The WLE reliability\n\nYou can look at the TAM documentation for more details, but for this example, we want to focus on the theta column, which contains the person estimates we need to create our Wright map.\nWe can get the data we need by selecting just that column:\n\nWLEestimates.mod1 &lt;- persons.mod1$theta\n\n\n\n\nAnd we can get our item estimates using the tam.threshold command.\n\nthresholds.mod1 &lt;- tam.threshold(mod1)\n\n\n\n\nWith these two matrices, we are ready to plot our Wright Map:\n\nwrightMap(WLEestimates.mod1, thresholds.mod1)\n\n\n\n\n\n\n\n\nAnd you can start editing it to make it nicer:\n\nwrightMap(WLEestimates.mod1, thresholds.mod1, show.thr.lab = FALSE, label.items = c(1:40), label.items.rows = 3)"
  },
  {
    "objectID": "website/example02.html#setup",
    "href": "website/example02.html#setup",
    "title": "Using WrightMap with the TAM Package",
    "section": "",
    "text": "Let’s start by loading TAM.\n\nlibrary(TAM)\n\nLoading required package: CDM\n\n\nLoading required package: mvtnorm\n\n\n**********************************\n** CDM 8.2-6 (2022-08-25 15:43:23)       \n** Cognitive Diagnostic Models  **\n**********************************\n\n\n* TAM 4.2-21 (2024-02-19 18:52:08)\n\n\nAnd we can use one of TAM’s simulated datasets (without any missing data in this case) for this example:\n\ndata(data.sim.rasch)\nstr(data.sim.rasch)\n\n num [1:2000, 1:40] 1 0 1 1 1 1 1 1 1 1 ...\n - attr(*, \"dimnames\")=List of 2\n  ..$ : NULL\n  ..$ : chr [1:40] \"I1\" \"I2\" \"I3\" \"I4\" ...\n\n\nA quick look with str confirms that we now have a simulated dataset with responses from 2000 persons (rows) to 40 items (columns). We are ready to go!"
  },
  {
    "objectID": "website/example02.html#analysis-with-tam",
    "href": "website/example02.html#analysis-with-tam",
    "title": "Using WrightMap with the TAM Package",
    "section": "",
    "text": "In this example, we will run a Rasch model using the TAM command tam.mml, which will estimate the model using a marginal maximum likelihood method.\n\nmod1 &lt;- tam.mml(resp=data.sim.rasch, verbose=FALSE)\n\nThe estimation should take very little time, and you should see a summary of the results and the total time it took to run the analysis."
  },
  {
    "objectID": "website/example02.html#person-estimates",
    "href": "website/example02.html#person-estimates",
    "title": "Using WrightMap with the TAM Package",
    "section": "",
    "text": "You can get person estimates in several ways in TAM, but for this example, I will use the tam.wle command, which produces Warm Likelihood Estimates (WLE) for each respondent.\n\npersons.mod1 &lt;- tam.wle(mod1)\n\nIteration in WLE/MLE estimation  1   | Maximal change  0.8281 \nIteration in WLE/MLE estimation  2   | Maximal change  0.4335 \nIteration in WLE/MLE estimation  3   | Maximal change  0.0883 \nIteration in WLE/MLE estimation  4   | Maximal change  7e-04 \nIteration in WLE/MLE estimation  5   | Maximal change  0 \n----\n WLE Reliability= 0.894 \n\nstr(persons.mod1)\n\nClasses 'tam.wle' and 'data.frame': 2000 obs. of  7 variables:\n $ pid         : int  1 2 3 4 5 6 7 8 9 10 ...\n $ N.items     : num  40 40 40 40 40 40 40 40 40 40 ...\n $ PersonScores: num  19 14 35 14 27 12 23 17 5 12 ...\n $ PersonMax   : num  40 40 40 40 40 40 40 40 40 40 ...\n $ theta       : num  -0.116 -0.791 2.373 -0.791 0.964 ...\n $ error       : num  0.366 0.377 0.498 0.377 0.382 ...\n $ WLE.rel     : num  0.894 0.894 0.894 0.894 0.894 ...\n - attr(*, \"ndim\")= int 1\n - attr(*, \"nobs\")= int 2000\n - attr(*, \"M_sq_error\")= Named num 0.165\n  ..- attr(*, \"names\")= chr \"Dim1\"\n - attr(*, \"WLEvar\")= Named num 1.55\n  ..- attr(*, \"names\")= chr \"Dim1\"\n - attr(*, \"WLEM\")= Named num 0.000865\n  ..- attr(*, \"names\")= chr \"Dim1\"\n - attr(*, \"WLE.rel\")= num 0.894\n - attr(*, \"call\")= language tam.wle(tamobj = mod1)\n\n\nIf we look at the resulting matrix, we can see that we have several columns, including:\n\npid: the ID of the respondent\nN.items: the number of items\nPersonScores: The score of each person\nPersonMax: The maximum possible score of each person\ntheta: The WLE estimate\nerror: The standard error of the WLE estimate\nWLE.rel: The WLE reliability\n\nYou can look at the TAM documentation for more details, but for this example, we want to focus on the theta column, which contains the person estimates we need to create our Wright map.\nWe can get the data we need by selecting just that column:\n\nWLEestimates.mod1 &lt;- persons.mod1$theta"
  },
  {
    "objectID": "website/example02.html#item-parameters",
    "href": "website/example02.html#item-parameters",
    "title": "Using WrightMap with the TAM Package",
    "section": "",
    "text": "And we can get our item estimates using the tam.threshold command.\n\nthresholds.mod1 &lt;- tam.threshold(mod1)"
  },
  {
    "objectID": "website/example02.html#creating-the-wright-map",
    "href": "website/example02.html#creating-the-wright-map",
    "title": "Using WrightMap with the TAM Package",
    "section": "",
    "text": "With these two matrices, we are ready to plot our Wright Map:\n\nwrightMap(WLEestimates.mod1, thresholds.mod1)\n\n\n\n\n\n\n\n\nAnd you can start editing it to make it nicer:\n\nwrightMap(WLEestimates.mod1, thresholds.mod1, show.thr.lab = FALSE, label.items = c(1:40), label.items.rows = 3)"
  },
  {
    "objectID": "website/example01.html",
    "href": "website/example01.html",
    "title": "Simulating Item Responses with the Partial Credit and Rasch Models",
    "section": "",
    "text": "In this tutorial, we’re going to explore how to simulate item responses using the sim.PCM function. This function is handy for generating polytomous item responses, allowing us to simulate responses for models like the Partial Credit Model (PCM) or even a Rasch model when dealing with dichotomous items.\nWhat’s great about sim.PCM is its flexibility—it lets you play around with different item levels, thresholds, and person abilities. Whether you want a simple Rasch model or a more complex situation where items have different numbers of categories, this function has you covered!\n\n\nLet’s start by simulating some basic data. We’ll begin with a simple setup: 100 respondents answering 5 items, each with 3 response levels (think of it like a Likert scale with three options).\n\n\nHere, we’re simulating responses for 100 people across 5 items, each with 3 response options. It’s as easy as that!\n\nsimulated_data &lt;- sim.PCM(pN = 100, iN = 5, lN = 3)\n\nJust like that, you’ve got your data! This gives you a simple matrix of simulated responses that match our configuration: 100 respondents answering 5 items, each with 3 response levels.\n\n\n\nWhat if you want more control over the item difficulty thresholds? You can pass in your own custom thresholds instead of letting the function generate them for you. Here’s how:\n\ncustom_delta &lt;- matrix(c(-0.5, -1, -2, 1, 0.5, 1), nrow = 3)\nsimulated_data_custom &lt;- sim.PCM(pN = 50, iN = 3, lN = 3, delta = custom_delta)\n\nIn this example, we’re specifying thresholds for 3 items. The custom_delta matrix defines how difficult each threshold is for the respective items. If you look at the output, you’ll see the responses simulated based on these difficulty levels.\n\n\n\nWhat about the people? Maybe you don’t want a standard normal distribution for their abilities. Let’s say you want a little more variety in the abilities of your respondents—no problem! You can also specify your own custom person abilities.\n\ncustom_theta &lt;- rnorm(100, mean = 0, sd = 1.5)\nsimulated_data_theta &lt;- sim.PCM(pN = 100, iN = 5, lN = 3, theta = custom_theta)\n\nHere, we’re generating a set of 100 person abilities (custom_theta) with a mean of 0 and a standard deviation of 1.5. This gives you more control over how the simulated people interact with the items in your test.\n\n\n\nNow let’s move from polytomous items to a Rasch model with dichotomous items. In this case, each item only has two possible responses. We’ll simulate data for 50 people, with abilities ranging from -3 to +3, responding to 10 items.\n\nrasch_theta &lt;- seq(-3, 3, length.out = 50)\nrasch_delta &lt;- matrix(c(0,1.5,0,-1,0,0.5,0,-0.5,0,1,0,-1.5,0,2,0,-2,0,0.8,0,-0.8), ncol = 2, byrow = TRUE)\nsimulated_rasch &lt;- sim.PCM(pN = 50, iN = 10, lN = 2, delta = rasch_delta, theta = rasch_theta)\n\nIn this simulation, we have a Rasch model with 10 items and 50 persons. The rasch_theta values span from -3 to 3, representing a range of person abilities. The rasch_delta matrix specifies the difficulty of each item.\n\n\n\nWhat if your items don’t all have the same number of response options? That’s where the itemLevels argument comes in handy. For example, let’s simulate a mix of items: some have 5 levels, some are dichotomous, and some have 3 levels.\n\nsimulated_mixed_levels &lt;- sim.PCM(pN = 50, iN = 10, lN = 5, \n                                  itemLevels = c(5, 5, 5, 5, 2, 2, 2, 3, 3, 3))\n\nHere we’re simulating responses for 10 items, with 4 items having 5 levels, 3 items being dichotomous, and 3 items having 3 levels. This kind of flexibility is great for simulating more realistic data, where items can have different response structures.\n\n\n\n\nThe sim.PCM function is a powerful tool for simulating item responses for both polytomous and dichotomous items. Whether you’re setting up a simple Rasch model, simulating items with multiple levels, or adding custom thresholds and person abilities, this function gives you the flexibility to generate realistic data tailored to your needs.\nNow that you’ve seen a few examples, you can start experimenting with different configurations to see what works best for your research or testing scenarios. Happy simulating!"
  },
  {
    "objectID": "website/example01.html#setting-up-the-simulation",
    "href": "website/example01.html#setting-up-the-simulation",
    "title": "Simulating Item Responses with the Partial Credit and Rasch Models",
    "section": "",
    "text": "Let’s start by simulating some basic data. We’ll begin with a simple setup: 100 respondents answering 5 items, each with 3 response levels (think of it like a Likert scale with three options).\n\n\nHere, we’re simulating responses for 100 people across 5 items, each with 3 response options. It’s as easy as that!\n\nsimulated_data &lt;- sim.PCM(pN = 100, iN = 5, lN = 3)\n\nJust like that, you’ve got your data! This gives you a simple matrix of simulated responses that match our configuration: 100 respondents answering 5 items, each with 3 response levels.\n\n\n\nWhat if you want more control over the item difficulty thresholds? You can pass in your own custom thresholds instead of letting the function generate them for you. Here’s how:\n\ncustom_delta &lt;- matrix(c(-0.5, -1, -2, 1, 0.5, 1), nrow = 3)\nsimulated_data_custom &lt;- sim.PCM(pN = 50, iN = 3, lN = 3, delta = custom_delta)\n\nIn this example, we’re specifying thresholds for 3 items. The custom_delta matrix defines how difficult each threshold is for the respective items. If you look at the output, you’ll see the responses simulated based on these difficulty levels.\n\n\n\nWhat about the people? Maybe you don’t want a standard normal distribution for their abilities. Let’s say you want a little more variety in the abilities of your respondents—no problem! You can also specify your own custom person abilities.\n\ncustom_theta &lt;- rnorm(100, mean = 0, sd = 1.5)\nsimulated_data_theta &lt;- sim.PCM(pN = 100, iN = 5, lN = 3, theta = custom_theta)\n\nHere, we’re generating a set of 100 person abilities (custom_theta) with a mean of 0 and a standard deviation of 1.5. This gives you more control over how the simulated people interact with the items in your test.\n\n\n\nNow let’s move from polytomous items to a Rasch model with dichotomous items. In this case, each item only has two possible responses. We’ll simulate data for 50 people, with abilities ranging from -3 to +3, responding to 10 items.\n\nrasch_theta &lt;- seq(-3, 3, length.out = 50)\nrasch_delta &lt;- matrix(c(0,1.5,0,-1,0,0.5,0,-0.5,0,1,0,-1.5,0,2,0,-2,0,0.8,0,-0.8), ncol = 2, byrow = TRUE)\nsimulated_rasch &lt;- sim.PCM(pN = 50, iN = 10, lN = 2, delta = rasch_delta, theta = rasch_theta)\n\nIn this simulation, we have a Rasch model with 10 items and 50 persons. The rasch_theta values span from -3 to 3, representing a range of person abilities. The rasch_delta matrix specifies the difficulty of each item.\n\n\n\nWhat if your items don’t all have the same number of response options? That’s where the itemLevels argument comes in handy. For example, let’s simulate a mix of items: some have 5 levels, some are dichotomous, and some have 3 levels.\n\nsimulated_mixed_levels &lt;- sim.PCM(pN = 50, iN = 10, lN = 5, \n                                  itemLevels = c(5, 5, 5, 5, 2, 2, 2, 3, 3, 3))\n\nHere we’re simulating responses for 10 items, with 4 items having 5 levels, 3 items being dichotomous, and 3 items having 3 levels. This kind of flexibility is great for simulating more realistic data, where items can have different response structures."
  },
  {
    "objectID": "website/example01.html#wrapping-up",
    "href": "website/example01.html#wrapping-up",
    "title": "Simulating Item Responses with the Partial Credit and Rasch Models",
    "section": "",
    "text": "The sim.PCM function is a powerful tool for simulating item responses for both polytomous and dichotomous items. Whether you’re setting up a simple Rasch model, simulating items with multiple levels, or adding custom thresholds and person abilities, this function gives you the flexibility to generate realistic data tailored to your needs.\nNow that you’ve seen a few examples, you can start experimenting with different configurations to see what works best for your research or testing scenarios. Happy simulating!"
  },
  {
    "objectID": "website/about.html",
    "href": "website/about.html",
    "title": "About WrightMap",
    "section": "",
    "text": "A powerful yet simple graphical tool available in the field of psychometrics is the Wright Map, which presents the location of both respondents and items on the same scale.\nWright Maps are commonly used to present the results of dichotomous or polytomous item response models. The WrightMap package provides functions to easily create these beautiful Wright Maps from item parameters and person estimates stored as R objects.\nThe plots can represent polytomoys and multidimensional models, are highly customizable, and as any other R plot, they can be exported into multiple image formats. Although the package can be used in conjunction with any software used to estimate the IRT model (e.g. eRm or IRToys in R, or Stata, Mplus, etc.), WrightMap features special integration with ConQuest to facilitate reading and plotting its output directly.\nWrightMap was created by David Torres Irribarra and Rebecca Freund."
  },
  {
    "objectID": "website/about.html#where-does-the-name-wright-map-comes-from",
    "href": "website/about.html#where-does-the-name-wright-map-comes-from",
    "title": "About WrightMap",
    "section": "Where does the name “Wright Map” comes from?",
    "text": "Where does the name “Wright Map” comes from?\nThese plots are named after Ben Wright for his contribution on using item maps to better understand measurement in the social sciences.\n\n“It seemed to me that, in fact, Ben had made his most significant contributions to measurement in the area of conceptualizing measures, and interpreting the results of measurement analyses, and that his central tool in doing so were these (many forms of) items maps.”\n— Mark Wilson on coining the name “Wright Map”\n\nYou can learn more about the origin of the term Wright Map here."
  },
  {
    "objectID": "website/about.html#where-can-you-get-wrightmap",
    "href": "website/about.html#where-can-you-get-wrightmap",
    "title": "About WrightMap",
    "section": "Where can you get WrightMap?",
    "text": "Where can you get WrightMap?\nYou can download the package and/or find more information about the package on the WrightMap page on CRAN. Alternatively, you can get the source code on our GitHub repository."
  },
  {
    "objectID": "website/about.html#wrightmap-tutorials",
    "href": "website/about.html#wrightmap-tutorials",
    "title": "About WrightMap",
    "section": "WrightMap tutorials",
    "text": "WrightMap tutorials\nYou can learn more about how to use WrightMap in our tutorials page here."
  }
]